{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQ6lx6XAaf4iTRE7u9XwJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeRuiKee/ml-dl-playground/blob/main/DNN_experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN Template code"
      ],
      "metadata": {
        "id": "cGSkfpFEAybb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),  # Input layer with 128 neurons and ReLU activation\n",
        "    Dense(64, activation='relu'),                                          # Hidden layer with 64 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "kO9Qrk0mA0NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSavio-OA5m-",
        "outputId": "fd7f5885-9f0e-491c-c8d9-b9e8e7c378a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2469 - accuracy: 0.9285\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1062 - accuracy: 0.9684\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0727 - accuracy: 0.9778\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0559 - accuracy: 0.9822\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0425 - accuracy: 0.9870\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9771\n",
            "Test accuracy: 0.9771000146865845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 activation, optimizer = adam"
      ],
      "metadata": {
        "id": "KDVUFey84tWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## relu"
      ],
      "metadata": {
        "id": "apJsUDB05X1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),  # Input layer with 128 neurons and relu activation\n",
        "    Dense(64, activation='relu'),                                          # Hidden layer with 64 neurons and relu activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxLXyd8U5T6G",
        "outputId": "2352260a-6205-4ec0-ee3f-941ffc6ce9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2395 - accuracy: 0.9296\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1020 - accuracy: 0.9687\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0707 - accuracy: 0.9783\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0553 - accuracy: 0.9824\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0415 - accuracy: 0.9864\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.9755\n",
            "Test accuracy: 0.9754999876022339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeakyReLU"
      ],
      "metadata": {
        "id": "UtB8YC1E5a4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='LeakyReLU', input_shape=(784,)),  # Input layer with 128 neurons and LeakyReLU activation\n",
        "    Dense(64, activation='LeakyReLU'),                                          # Hidden layer with 64 neurons and LeakyReLU activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_atSP2O5jkx",
        "outputId": "f1b85fa4-2933-4f8d-817c-3ccfd5513b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2693 - accuracy: 0.9223\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1327 - accuracy: 0.9603\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0980 - accuracy: 0.9698\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0794 - accuracy: 0.9744\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0663 - accuracy: 0.9790\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1066 - accuracy: 0.9698\n",
            "Test accuracy: 0.9697999954223633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## elu"
      ],
      "metadata": {
        "id": "mBsOHY3K5pjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='elu', input_shape=(784,)),  # Input layer with 128 neurons and elu activation\n",
        "    Dense(64, activation='elu'),                                          # Hidden layer with 64 neurons and elu activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqvyDufU5rSv",
        "outputId": "621986d9-3da6-47db-861e-1c2679de50db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2561 - accuracy: 0.9252\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1172 - accuracy: 0.9640\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0805 - accuracy: 0.9747\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0604 - accuracy: 0.9810\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0465 - accuracy: 0.9851\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9745\n",
            "Test accuracy: 0.9745000004768372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PReLU"
      ],
      "metadata": {
        "id": "j5xyRpBs5rpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='PReLU', input_shape=(784,)),  # Input layer with 128 neurons and PReLU activation\n",
        "    Dense(64, activation='PReLU'),                                          # Hidden layer with 64 neurons and PReLU activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dYdoN705ueE",
        "outputId": "5e90851e-3ca8-4bb4-94b3-5b6fd3f606f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2407 - accuracy: 0.9291\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1019 - accuracy: 0.9689\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0690 - accuracy: 0.9788\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0507 - accuracy: 0.9843\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0436 - accuracy: 0.9857\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9741\n",
            "Test accuracy: 0.9740999937057495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "WZXxOPZc5u7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='sigmoid', input_shape=(784,)),  # Input layer with 128 neurons and sigmoid activation\n",
        "    Dense(64, activation='sigmoid'),                                          # Hidden layer with 64 neurons and sigmoid activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkGlvYmPz27n",
        "outputId": "e11e25c9-a2bd-424b-b92f-119013ac676a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4720 - accuracy: 0.8834\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1787 - accuracy: 0.9471\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1241 - accuracy: 0.9633\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0932 - accuracy: 0.9721\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0724 - accuracy: 0.9785\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9726\n",
            "Test accuracy: 0.972599983215332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tanh"
      ],
      "metadata": {
        "id": "np0lEyVn5wzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ87nfXz5x98",
        "outputId": "7edeea9f-7b26-4f44-e161-779d71e31556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2616 - accuracy: 0.9245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1193 - accuracy: 0.9640\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0798 - accuracy: 0.9762\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0591 - accuracy: 0.9822\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0442 - accuracy: 0.9865\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0708 - accuracy: 0.9778\n",
            "Test accuracy: 0.9778000116348267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## softmax"
      ],
      "metadata": {
        "id": "zhkb0S5K5ygf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='softmax', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='softmax'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwzT5Dfw5zVG",
        "outputId": "d94fe5e7-849b-47f3-9744-e5850d5b0d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6436 - accuracy: 0.6841\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6323 - accuracy: 0.8456\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4599 - accuracy: 0.8788\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3777 - accuracy: 0.9078\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3248 - accuracy: 0.9204\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.9220\n",
            "Test accuracy: 0.921999990940094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best activation function = tanh . Test accuracy: 0.9778000116348267"
      ],
      "metadata": {
        "id": "eunbQjFz5z8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best activation function: tanh, 8 optimizer"
      ],
      "metadata": {
        "id": "Wg7yt-1N5-cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD"
      ],
      "metadata": {
        "id": "0-AxWstZ6DKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9pFqDPw1Njq",
        "outputId": "735ccd50-3a3c-44d3-805a-28d742413646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6023 - accuracy: 0.8466\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3237 - accuracy: 0.9090\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2755 - accuracy: 0.9209\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2448 - accuracy: 0.9291\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2208 - accuracy: 0.9358\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2073 - accuracy: 0.9414\n",
            "Test accuracy: 0.9413999915122986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD with Momentum"
      ],
      "metadata": {
        "id": "GSblCY4l6EaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm,\n",
        "              loss='sparse_categorical_crossentropy',  # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkVr-iCd6IIt",
        "outputId": "e63ff441-11b5-4583-dddd-13dabdad58c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2956 - accuracy: 0.9135\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1451 - accuracy: 0.9570\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1051 - accuracy: 0.9680\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0804 - accuracy: 0.9757\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0651 - accuracy: 0.9804\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9738\n",
            "Test accuracy: 0.973800003528595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "o3P1ff9H6I5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3y2-wz76Ki4",
        "outputId": "f8976994-ae3f-400d-e26c-dc277247bae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2614 - accuracy: 0.9243\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1247 - accuracy: 0.9623\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0869 - accuracy: 0.9740\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0665 - accuracy: 0.9797\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0512 - accuracy: 0.9845\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0795 - accuracy: 0.9756\n",
            "Test accuracy: 0.975600004196167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adam"
      ],
      "metadata": {
        "id": "gpbqiVYh6LA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blr2I5A56MGz",
        "outputId": "541cb4bc-e9d9-4794-8e5a-8e9372549915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2620 - accuracy: 0.9224\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1193 - accuracy: 0.9646\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0802 - accuracy: 0.9756\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0586 - accuracy: 0.9816\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0448 - accuracy: 0.9865\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9740\n",
            "Test accuracy: 0.9739999771118164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adamax"
      ],
      "metadata": {
        "id": "n6d1yKGM6Meb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adamax',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXedH9OD6NZb",
        "outputId": "704e7c17-7c8a-470e-b609-c10fcb2c1832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3509 - accuracy: 0.9034\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1931 - accuracy: 0.9445\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1459 - accuracy: 0.9574\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1175 - accuracy: 0.9660\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0983 - accuracy: 0.9717\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1023 - accuracy: 0.9678\n",
            "Test accuracy: 0.9678000211715698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nadam"
      ],
      "metadata": {
        "id": "7koKqV5y6Nvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='nadam',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyvR2wAL6OpS",
        "outputId": "e94b999c-a895-46b3-f2e6-502e57a00e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2615 - accuracy: 0.9247\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1199 - accuracy: 0.9641\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0805 - accuracy: 0.9756\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0602 - accuracy: 0.9808\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0454 - accuracy: 0.9860\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9736\n",
            "Test accuracy: 0.9735999703407288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad"
      ],
      "metadata": {
        "id": "CXfS5s__6O5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='AdaGrad',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk3lPypP6QCw",
        "outputId": "e8e85171-8ffb-4f00-86c0-6ad02fbc2a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0631 - accuracy: 0.7508\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5773 - accuracy: 0.8634\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4749 - accuracy: 0.8817\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4246 - accuracy: 0.8904\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3934 - accuracy: 0.8965\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.9041\n",
            "Test accuracy: 0.9041000008583069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaDelta"
      ],
      "metadata": {
        "id": "BfqAXBmy6Sfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='AdaDelta',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B19KhPvH6Tex",
        "outputId": "d6bdaa88-0986-4a19-8dc8-769c6666d9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.1853 - accuracy: 0.2245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.9132 - accuracy: 0.4396\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.6886 - accuracy: 0.5749\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5036 - accuracy: 0.6551\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.3531 - accuracy: 0.7050\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2709 - accuracy: 0.7279\n",
            "Test accuracy: 0.7279000282287598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best optimizer = RMSProp . Test accuracy: 0.975600004196167"
      ],
      "metadata": {
        "id": "Zlj1X8a36UeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting Best Output Activation Function\n",
        "\n",
        "Using Best activation function: tanh and Best optimizer: RMSProp"
      ],
      "metadata": {
        "id": "Iqith1cp6Xyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output relu"
      ],
      "metadata": {
        "id": "Wwv1dI9n6feW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='relu')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdfwLojH6a5g",
        "outputId": "ead4196a-768a-4196-932c-d9290a59c627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3201 - accuracy: 0.1210\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.2733 - accuracy: 0.1122\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2678 - accuracy: 0.1142\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3013 - accuracy: 0.0993\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2814 - accuracy: 0.1080\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.2646 - accuracy: 0.1145\n",
            "Test accuracy: 0.1145000010728836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output  LeakyReLU"
      ],
      "metadata": {
        "id": "0dYP2v086jqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='LeakyReLU')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65tCV9VB4Zv_",
        "outputId": "f65f90ef-a32d-49bd-f622-2249da066733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3326 - accuracy: 0.2416\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.2307\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3025 - accuracy: 0.2307\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.2307\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3025 - accuracy: 0.2307\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.2298\n",
            "Test accuracy: 0.2298000007867813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output elu"
      ],
      "metadata": {
        "id": "LaamkHP_6kSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='elu')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImCvddmH6m1Q",
        "outputId": "0c2e298f-a414-4b91-a604-8fe4c8135bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3547 - accuracy: 0.2643\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3024 - accuracy: 0.2432\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3024 - accuracy: 0.2432\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3024 - accuracy: 0.2433\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3024 - accuracy: 0.2432\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.2328\n",
            "Test accuracy: 0.23280000686645508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output PReLU"
      ],
      "metadata": {
        "id": "YQIAbYz16nWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='PReLU')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ttXTNH6pRU",
        "outputId": "735d50fd-9709-484b-d438-477354b16326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3414 - accuracy: 0.1006\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3018 - accuracy: 0.0991\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0980\n",
            "Test accuracy: 0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output sigmoid"
      ],
      "metadata": {
        "id": "-JeXv8Q-6qRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='sigmoid')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0i27M736rcf",
        "outputId": "89cb4d76-71e0-4c50-e233-94cf005ed435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2575 - accuracy: 0.9254\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1207 - accuracy: 0.9628\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.9740\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0644 - accuracy: 0.9808\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0501 - accuracy: 0.9847\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9778\n",
            "Test accuracy: 0.9778000116348267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output tanh"
      ],
      "metadata": {
        "id": "ajTF2JpB6rwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='tanh')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGYehcxy6srr",
        "outputId": "ef31f4a2-32fd-4678-b3bb-ba0e9055ebb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3083 - accuracy: 0.2997\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3025 - accuracy: 0.2860\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3025 - accuracy: 0.2875\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.2875\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.2876\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.2859\n",
            "Test accuracy: 0.2858999967575073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output softmax"
      ],
      "metadata": {
        "id": "BFPX477H6tCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Define the architecture of the DNN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(784,)),  # Input layer with 128 neurons and tanh activation\n",
        "    Dense(64, activation='tanh'),                                          # Hidden layer with 64 neurons and tanh activation\n",
        "    Dense(10, activation='softmax')                                    # Output layer with 10 neurons for classification (softmax activation)\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='sparse_categorical_crossentropy',           # Using cross-entropy loss for classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load data (example: MNIST dataset)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
        "# Flatten the data\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "# Train the model\n",
        "model.fit(x_train_flattened, y_train, epochs=5)\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O9Kp8_E6uI2",
        "outputId": "513ef5b5-b262-4565-e205-fad8e3934cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 0.2598 - accuracy: 0.9246\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1229 - accuracy: 0.9633\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0852 - accuracy: 0.9745\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0657 - accuracy: 0.9801\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0511 - accuracy: 0.9845\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9725\n",
            "Test accuracy: 0.9725000262260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best output activation function: sigmoid. Test accuracy: 0.9778000116348267"
      ],
      "metadata": {
        "id": "BDq4W37E6ugj"
      }
    }
  ]
}