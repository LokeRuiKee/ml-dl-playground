{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/282ufRmTxwWn+HKwkXZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeRuiKee/ml-dl-playground/blob/main/RNN_experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Template Code"
      ],
      "metadata": {
        "id": "xwH6F-GMLGOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# Define the sequence length and number of features\n",
        "sequence_length = 10\n",
        "num_features = 1\n",
        "# assume each element in the sequence is a single feature\n",
        "# Generate some sample sequential data\n",
        "X_train = np.random.randn(100, sequence_length, num_features)\n",
        "y_train = np.random.randint(0, 2, size=(100,))\n",
        "# Binary classification task, random labels for demonstration\n",
        "# randn: NumPy function used to generate an array of random numbers\n",
        "# from a standard normal distribution (mean = 0, standard deviation = 1)\n",
        "# randint: NumPy function used to generate random integers\n",
        "# within a specified range"
      ],
      "metadata": {
        "id": "BFRjJ6S0LHWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=(sequence_length, num_features)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "# Once trained, you can use the model for predictions\n",
        "# For example:\n",
        "# predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmTF-pZuLViL",
        "outputId": "c0980056-4618-4d21-f633-74f0389057c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 7ms/step - loss: 0.7026 - accuracy: 0.5100\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.5500\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6725 - accuracy: 0.6100\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6655 - accuracy: 0.6100\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6592 - accuracy: 0.6100\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6537 - accuracy: 0.6200\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6476 - accuracy: 0.6400\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6407 - accuracy: 0.6300\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6347 - accuracy: 0.6100\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ee6369a2590>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 activation, optimizer = adam"
      ],
      "metadata": {
        "id": "PTWfC9AGOFJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## relu"
      ],
      "metadata": {
        "id": "u4Gd4A23OHmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'relu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn_xNJo9rKxG",
        "outputId": "93538324-9f80-4b7d-836f-f4d80cafd7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 11ms/step - loss: 1.3311 - accuracy: 0.5158 - val_loss: 0.7825 - val_accuracy: 0.7362\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.6660 - accuracy: 0.7854 - val_loss: 0.5357 - val_accuracy: 0.8292\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.5034 - accuracy: 0.8445 - val_loss: 0.4229 - val_accuracy: 0.8764\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4200 - accuracy: 0.8739 - val_loss: 0.3754 - val_accuracy: 0.8898\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3711 - accuracy: 0.8893 - val_loss: 0.3375 - val_accuracy: 0.9021\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8966\n",
            "Test Loss:  0.3319472372531891\n",
            "Test Accuracy:  0.8966000080108643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeakyReLU"
      ],
      "metadata": {
        "id": "P4KXsgOBOJ1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'LeakyReLU'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPaLCQ7JtXgT",
        "outputId": "6e31ade8-587c-4120-e1e9-ab7cd1ca6fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 6s 12ms/step - loss: 1.1511 - accuracy: 0.5963 - val_loss: 0.6466 - val_accuracy: 0.7747\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.6169 - accuracy: 0.7944 - val_loss: 0.5002 - val_accuracy: 0.8398\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4916 - accuracy: 0.8442 - val_loss: 0.4165 - val_accuracy: 0.8666\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.4188 - accuracy: 0.8695 - val_loss: 0.3602 - val_accuracy: 0.8907\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3712 - accuracy: 0.8881 - val_loss: 0.3083 - val_accuracy: 0.9079\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.3116 - accuracy: 0.9038\n",
            "Test Loss:  0.3115786612033844\n",
            "Test Accuracy:  0.9038000106811523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## elu"
      ],
      "metadata": {
        "id": "mm2tuhZTON07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDzRa1UovQ5D",
        "outputId": "f8b59016-58b3-4933-dc34-3de18cf7121a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 1.0795 - accuracy: 0.6515 - val_loss: 0.5820 - val_accuracy: 0.8171\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.5004 - accuracy: 0.8484 - val_loss: 0.3999 - val_accuracy: 0.8807\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.3966 - accuracy: 0.8793 - val_loss: 0.3419 - val_accuracy: 0.8994\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3544 - accuracy: 0.8926 - val_loss: 0.3054 - val_accuracy: 0.9102\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3189 - accuracy: 0.9039 - val_loss: 0.2911 - val_accuracy: 0.9129\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.9102\n",
            "Test Loss:  0.2998817265033722\n",
            "Test Accuracy:  0.9101999998092651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PReLU"
      ],
      "metadata": {
        "id": "VDEWlx8UOO2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'PReLU'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp0CqgLNvSYx",
        "outputId": "0aa6ab29-a989-4cba-c943-d4023b3df90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 11ms/step - loss: 1.2793 - accuracy: 0.5543 - val_loss: 0.7745 - val_accuracy: 0.7333\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 11s 30ms/step - loss: 0.6984 - accuracy: 0.7718 - val_loss: 0.5570 - val_accuracy: 0.8149\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4997 - accuracy: 0.8476 - val_loss: 0.4105 - val_accuracy: 0.8731\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3955 - accuracy: 0.8832 - val_loss: 0.3246 - val_accuracy: 0.9035\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.3406 - accuracy: 0.8987 - val_loss: 0.2924 - val_accuracy: 0.9104\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3123 - accuracy: 0.9065\n",
            "Test Loss:  0.31234365701675415\n",
            "Test Accuracy:  0.906499981880188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "XqCOsPB_ORQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'sigmoid'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMs_2CUgvT2h",
        "outputId": "c983c63f-1aeb-4c30-f4e5-8b92c28d1f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 7s 13ms/step - loss: 2.2841 - accuracy: 0.1558 - val_loss: 2.1618 - val_accuracy: 0.2624\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.9302 - accuracy: 0.2995 - val_loss: 1.7839 - val_accuracy: 0.3292\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.7700 - accuracy: 0.3486 - val_loss: 1.7167 - val_accuracy: 0.3363\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.7297 - accuracy: 0.3510 - val_loss: 1.6888 - val_accuracy: 0.3512\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.7048 - accuracy: 0.3543 - val_loss: 1.6662 - val_accuracy: 0.3595\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7021 - accuracy: 0.3429\n",
            "Test Loss:  1.702112078666687\n",
            "Test Accuracy:  0.34290000796318054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tanh"
      ],
      "metadata": {
        "id": "pRROg9LDOTTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'tanh'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_acGrNgvVNA",
        "outputId": "fc2ca23a-0da4-4cec-a3a0-2dc526f25ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 1.3672 - accuracy: 0.5425 - val_loss: 0.8915 - val_accuracy: 0.7138\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.7893 - accuracy: 0.7436 - val_loss: 0.6193 - val_accuracy: 0.8142\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5989 - accuracy: 0.8195 - val_loss: 0.5093 - val_accuracy: 0.8495\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4930 - accuracy: 0.8577 - val_loss: 0.4388 - val_accuracy: 0.8742\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4298 - accuracy: 0.8749 - val_loss: 0.3889 - val_accuracy: 0.8898\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4027 - accuracy: 0.8860\n",
            "Test Loss:  0.40266937017440796\n",
            "Test Accuracy:  0.8859999775886536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## softmax"
      ],
      "metadata": {
        "id": "4iuT7TlXOUX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'softmax'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbOoUkrwvWhy",
        "outputId": "8fe93803-7066-4642-9719-82f6a3bc672e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 6s 11ms/step - loss: 2.3012 - accuracy: 0.1116 - val_loss: 2.3001 - val_accuracy: 0.1091\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2879 - accuracy: 0.1473 - val_loss: 2.2491 - val_accuracy: 0.1783\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.1448 - accuracy: 0.2189 - val_loss: 2.0407 - val_accuracy: 0.2620\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.9964 - accuracy: 0.2316 - val_loss: 1.9483 - val_accuracy: 0.2673\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.9274 - accuracy: 0.2612 - val_loss: 1.8881 - val_accuracy: 0.3252\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 1.9007 - accuracy: 0.3146\n",
            "Test Loss:  1.9007335901260376\n",
            "Test Accuracy:  0.31459999084472656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "\n",
        "Best activation function: elu, Test Accuracy:  0.9101999998092651"
      ],
      "metadata": {
        "id": "O1BH0zv_OugI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best activation function: elu, 8 optimizer"
      ],
      "metadata": {
        "id": "EfMjhjKqOZWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD"
      ],
      "metadata": {
        "id": "Z0sqwYsrOcKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKK83ukxOcfo",
        "outputId": "d641dcfb-4c70-4bd9-877c-ba4b44d5ddca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.7769 - accuracy: 0.3989 - val_loss: 1.1593 - val_accuracy: 0.5932\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.9900 - accuracy: 0.6543 - val_loss: 0.8508 - val_accuracy: 0.6989\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.7666 - accuracy: 0.7392 - val_loss: 0.8339 - val_accuracy: 0.6955\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6393 - accuracy: 0.7827 - val_loss: 0.5151 - val_accuracy: 0.8261\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.5684 - accuracy: 0.8053 - val_loss: 0.4585 - val_accuracy: 0.8436\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4723 - accuracy: 0.8429\n",
            "Test Loss:  0.47225525975227356\n",
            "Test Accuracy:  0.8428999781608582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD with Momentum"
      ],
      "metadata": {
        "id": "5lO5MGApOcx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ky7B9fDOeCB",
        "outputId": "b5068645-f593-40c6-9233-2ca9048c49f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 0.9315 - accuracy: 0.6812 - val_loss: 0.5775 - val_accuracy: 0.8242\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4700 - accuracy: 0.8565 - val_loss: 0.3108 - val_accuracy: 0.9094\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3639 - accuracy: 0.8935 - val_loss: 0.2960 - val_accuracy: 0.9178\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.3033 - accuracy: 0.9113 - val_loss: 0.2206 - val_accuracy: 0.9347\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2554 - accuracy: 0.9253 - val_loss: 0.2319 - val_accuracy: 0.9327\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9248\n",
            "Test Loss:  0.25216323137283325\n",
            "Test Accuracy:  0.9247999787330627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "9Uc0DF1eOe8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl1Int2DOgyp",
        "outputId": "2bdd6114-ebff-42e7-fd27-48ea53df6324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 6s 13ms/step - loss: 1.0421 - accuracy: 0.6525 - val_loss: 0.6515 - val_accuracy: 0.7911\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.6086 - accuracy: 0.8021 - val_loss: 0.4660 - val_accuracy: 0.8506\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4652 - accuracy: 0.8559 - val_loss: 0.3916 - val_accuracy: 0.8851\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3806 - accuracy: 0.8857 - val_loss: 0.3354 - val_accuracy: 0.9032\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3323 - accuracy: 0.9013 - val_loss: 0.2772 - val_accuracy: 0.9183\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.9214\n",
            "Test Loss:  0.27042049169540405\n",
            "Test Accuracy:  0.9214000105857849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adam"
      ],
      "metadata": {
        "id": "HRrdRiD_OhKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI5l0ezIOilZ",
        "outputId": "24f446d9-dfe4-46d1-e522-29629144bfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 0.9820 - accuracy: 0.6658 - val_loss: 0.4918 - val_accuracy: 0.8448\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4649 - accuracy: 0.8566 - val_loss: 0.3971 - val_accuracy: 0.8764\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3810 - accuracy: 0.8830 - val_loss: 0.3601 - val_accuracy: 0.8898\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3335 - accuracy: 0.8982 - val_loss: 0.2919 - val_accuracy: 0.9115\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.3012 - accuracy: 0.9075 - val_loss: 0.2723 - val_accuracy: 0.9178\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9132\n",
            "Test Loss:  0.28041738271713257\n",
            "Test Accuracy:  0.9132000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adamax"
      ],
      "metadata": {
        "id": "HzeuRi3DOjEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='Adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrw_SDHbOmWl",
        "outputId": "2e29852b-9ec2-457b-81dd-93a917107df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 1.3459 - accuracy: 0.5323 - val_loss: 0.7872 - val_accuracy: 0.7459\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.6801 - accuracy: 0.7771 - val_loss: 0.5402 - val_accuracy: 0.8263\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5355 - accuracy: 0.8261 - val_loss: 0.4592 - val_accuracy: 0.8548\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.4631 - accuracy: 0.8529 - val_loss: 0.4128 - val_accuracy: 0.8691\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 5s 15ms/step - loss: 0.4123 - accuracy: 0.8720 - val_loss: 0.3643 - val_accuracy: 0.8887\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3870 - accuracy: 0.8800\n",
            "Test Loss:  0.38695552945137024\n",
            "Test Accuracy:  0.8799999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nadam"
      ],
      "metadata": {
        "id": "PjVHmK5nOnkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='Nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlOPIxcOOoQo",
        "outputId": "45b5e7b4-833d-44e2-c4b0-9506e033426f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 6s 11ms/step - loss: 0.9771 - accuracy: 0.6699 - val_loss: 0.4766 - val_accuracy: 0.8523\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4589 - accuracy: 0.8601 - val_loss: 0.3738 - val_accuracy: 0.8857\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.3767 - accuracy: 0.8873 - val_loss: 0.3161 - val_accuracy: 0.9058\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.3273 - accuracy: 0.9017 - val_loss: 0.2815 - val_accuracy: 0.9139\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.2974 - accuracy: 0.9121 - val_loss: 0.2639 - val_accuracy: 0.9208\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.9197\n",
            "Test Loss:  0.2693077027797699\n",
            "Test Accuracy:  0.919700026512146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad"
      ],
      "metadata": {
        "id": "XhZUZjeBOon2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='AdaGrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXGJkzo_Oqv3",
        "outputId": "393d70e8-3adc-49bd-b914-85b2e369d330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 2.2252 - accuracy: 0.2140 - val_loss: 2.0808 - val_accuracy: 0.2888\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.9569 - accuracy: 0.3225 - val_loss: 1.8016 - val_accuracy: 0.3997\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.7061 - accuracy: 0.4341 - val_loss: 1.5805 - val_accuracy: 0.4880\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.5309 - accuracy: 0.4966 - val_loss: 1.4366 - val_accuracy: 0.5328\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 1.4147 - accuracy: 0.5303 - val_loss: 1.3361 - val_accuracy: 0.5584\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3659 - accuracy: 0.5452\n",
            "Test Loss:  1.3658630847930908\n",
            "Test Accuracy:  0.545199990272522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaDelta"
      ],
      "metadata": {
        "id": "PpS8j1AGOsBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='AdaDelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SerL1emoOtGz",
        "outputId": "defb5086-0bb2-4adf-a1ac-7109ea5c22be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 2.5800 - accuracy: 0.1105 - val_loss: 2.5310 - val_accuracy: 0.1164\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.5120 - accuracy: 0.1174 - val_loss: 2.4694 - val_accuracy: 0.1245\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.4556 - accuracy: 0.1241 - val_loss: 2.4189 - val_accuracy: 0.1316\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.4092 - accuracy: 0.1330 - val_loss: 2.3777 - val_accuracy: 0.1379\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3717 - accuracy: 0.1416 - val_loss: 2.3446 - val_accuracy: 0.1469\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3562 - accuracy: 0.1462\n",
            "Test Loss:  2.3562207221984863\n",
            "Test Accuracy:  0.1462000012397766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best optimizer: SGD with Momentum. Test Accuracy:  0.9247999787330627"
      ],
      "metadata": {
        "id": "Kw9HbHDoOys-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting Best Output Activation Function\n"
      ],
      "metadata": {
        "id": "pGgf7ZiHPNer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output relu"
      ],
      "metadata": {
        "id": "Xn5guquWPrUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='relu')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpcphgclkm-G",
        "outputId": "d3247cbf-d211-4b7e-d6f8-061383604945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 2.5163 - accuracy: 0.1616 - val_loss: 2.2710 - val_accuracy: 0.1674\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: nan - accuracy: 0.1189 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 6s 15ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 5s 14ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 2s 5ms/step - loss: nan - accuracy: 0.0980\n",
            "Test Loss:  nan\n",
            "Test Accuracy:  0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output LeakyReLU"
      ],
      "metadata": {
        "id": "n0_PvICMkoAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='LeakyReLU')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1r_Y6jjkqVz",
        "outputId": "b0e7251f-2f3c-4658-bc94-2e4d30ba8fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 7s 13ms/step - loss: 6.2256 - accuracy: 0.1001 - val_loss: 4.9156 - val_accuracy: 0.1060\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 7.5089 - accuracy: 0.0972 - val_loss: 9.7635 - val_accuracy: 0.0914\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 9.7971 - accuracy: 0.0901 - val_loss: 9.7635 - val_accuracy: 0.0914\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 9.8740 - accuracy: 0.0901 - val_loss: 9.7635 - val_accuracy: 0.0914\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 9.8740 - accuracy: 0.0901 - val_loss: 9.7635 - val_accuracy: 0.0914\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 9.9029 - accuracy: 0.0892\n",
            "Test Loss:  9.902948379516602\n",
            "Test Accuracy:  0.08919999748468399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output elu"
      ],
      "metadata": {
        "id": "55RK6xVFkrDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='elu')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv99vjG-y9ca",
        "outputId": "e0ce2964-bc55-48c3-bd4e-dd747692d0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 11ms/step - loss: nan - accuracy: 0.0975 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0980\n",
            "Test Loss:  nan\n",
            "Test Accuracy:  0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output PReLU"
      ],
      "metadata": {
        "id": "UrDpezYKsqXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='PReLU')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo2UXsyQksJp",
        "outputId": "fe1aef3f-1d09-4f3c-86b9-bac1df82edc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 3.2526 - accuracy: 0.0971 - val_loss: 2.9254 - val_accuracy: 0.0998\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0980\n",
            "Test Loss:  nan\n",
            "Test Accuracy:  0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output sigmoid"
      ],
      "metadata": {
        "id": "-8-W30U0ktDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='sigmoid')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ee4gW0ekuPq",
        "outputId": "4841b7ab-24be-4c4b-e5a6-7f9de09ba099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 0.9174 - accuracy: 0.6975 - val_loss: 0.4460 - val_accuracy: 0.8697\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4988 - accuracy: 0.8479 - val_loss: 0.4447 - val_accuracy: 0.8721\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.4230 - accuracy: 0.8728 - val_loss: 0.3291 - val_accuracy: 0.9057\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.3574 - accuracy: 0.8931 - val_loss: 0.2979 - val_accuracy: 0.9112\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.3258 - accuracy: 0.9047 - val_loss: 0.2640 - val_accuracy: 0.9262\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2627 - accuracy: 0.9242\n",
            "Test Loss:  0.2627376616001129\n",
            "Test Accuracy:  0.9241999983787537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output tanh"
      ],
      "metadata": {
        "id": "i75ARhsakufy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='tanh')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cgyh2kckv0F",
        "outputId": "defe1d2e-11d0-4473-bff5-6b2e92825b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 7s 16ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0980\n",
            "Test Loss:  nan\n",
            "Test Accuracy:  0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output softmax"
      ],
      "metadata": {
        "id": "S0FrkwUdkwpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28) / 255.0  # Reshape and normalize training data\n",
        "x_test = x_test.reshape(-1, 28, 28) / 255.0    # Reshape and normalize test data\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode training labels\n",
        "y_test = to_categorical(y_test, num_classes=10)    # One-hot encode test labels\n",
        "\n",
        "# Step 2: Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(32, input_shape=(28, 28), activation = 'elu'),  # RNN layer with 32 units\n",
        "    Dense(10, activation='softmax')       # Output layer with 10 units for 10 classes\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "SGDm = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=SGDm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mplnn2SOkyGw",
        "outputId": "150b3d26-e1c1-4d47-b2d3-8760ea8f7d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 7s 13ms/step - loss: 0.9872 - accuracy: 0.6695 - val_loss: 0.4861 - val_accuracy: 0.8523\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.4803 - accuracy: 0.8543 - val_loss: 0.4455 - val_accuracy: 0.8660\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.3771 - accuracy: 0.8885 - val_loss: 0.3034 - val_accuracy: 0.9112\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.3461 - accuracy: 0.8989 - val_loss: 0.2799 - val_accuracy: 0.9179\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.3259 - accuracy: 0.9051 - val_loss: 0.3365 - val_accuracy: 0.8987\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8864\n",
            "Test Loss:  0.3836445212364197\n",
            "Test Accuracy:  0.8863999843597412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best output activation function: sigmoid. Test Accuracy:  0.9241999983787537"
      ],
      "metadata": {
        "id": "yTr2VOeIz5K9"
      }
    }
  ]
}