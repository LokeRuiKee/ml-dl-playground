{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsGE+6b48D6UVlyxeGIzaQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeRuiKee/ml-dl-playground/blob/main/GAN_experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Template Code"
      ],
      "metadata": {
        "id": "ZCsyPPWELZyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "F7wmLA0hLanO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "VY6352aMLfXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n"
      ],
      "metadata": {
        "id": "RRK3H-6cLjf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBqgIyBhQ9ly",
        "outputId": "436152d4-0406-4970-fb2b-a785adb28946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.5023490190505981, Generator Loss: 1.774107575416565\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.4587470665574074, Generator Loss: 2.231952428817749\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.475782111287117, Generator Loss: 2.683269500732422\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.389856293797493, Generator Loss: 3.0650861263275146\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.4386894963681698, Generator Loss: 3.4051804542541504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.4262126889079809, Generator Loss: 3.681575298309326\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.36120539251714945, Generator Loss: 3.901822090148926\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.3681684359908104, Generator Loss: 4.093732833862305\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.43004276789724827, Generator Loss: 4.252416610717773\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.3575878497213125, Generator Loss: 4.3578386306762695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.4127969015389681, Generator Loss: 4.468268394470215\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.3871809206902981, Generator Loss: 4.529452323913574\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.3018563278019428, Generator Loss: 4.5767974853515625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.41598012018948793, Generator Loss: 4.60322380065918\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.36028193589299917, Generator Loss: 4.61652946472168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.3930967156775296, Generator Loss: 4.626313209533691\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.3242698758840561, Generator Loss: 4.647966384887695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.39449375681579113, Generator Loss: 4.6306986808776855\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.39209130639210343, Generator Loss: 4.616189002990723\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.35306318663060665, Generator Loss: 4.633866786956787\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.3155007725581527, Generator Loss: 4.60263729095459\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.3356811301782727, Generator Loss: 4.556792259216309\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.33811390632763505, Generator Loss: 4.5738420486450195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.2686645733192563, Generator Loss: 4.527345657348633\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.2989936815574765, Generator Loss: 4.493137836456299\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.2792951725423336, Generator Loss: 4.499433517456055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.2993984632194042, Generator Loss: 4.4552812576293945\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.2779859211295843, Generator Loss: 4.4309797286987305\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.2919216938316822, Generator Loss: 4.382770538330078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.22897823667153716, Generator Loss: 4.402059555053711\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.2837107963860035, Generator Loss: 4.372341156005859\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.26809096382930875, Generator Loss: 4.343645095825195\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.1936774468049407, Generator Loss: 4.376777648925781\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.2978807482868433, Generator Loss: 4.314976692199707\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.2560926559381187, Generator Loss: 4.277921199798584\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.2811062103137374, Generator Loss: 4.305730819702148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.3018990522250533, Generator Loss: 4.2565226554870605\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.20557133806869388, Generator Loss: 4.25456428527832\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.23890488874167204, Generator Loss: 4.252954959869385\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.24598677456378937, Generator Loss: 4.240006446838379\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.22245701868087053, Generator Loss: 4.216689109802246\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.2171761691570282, Generator Loss: 4.222414970397949\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.2592123746871948, Generator Loss: 4.200533866882324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.23348496202379465, Generator Loss: 4.203640937805176\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.21716649597510695, Generator Loss: 4.200629234313965\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.2345069721341133, Generator Loss: 4.1439361572265625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.16856584697961807, Generator Loss: 4.15287971496582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.2201691884547472, Generator Loss: 4.243714332580566\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.1902823131531477, Generator Loss: 4.159958839416504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.2332860236056149, Generator Loss: 4.191237449645996\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.18666436150670052, Generator Loss: 4.206130027770996\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.15309148747473955, Generator Loss: 4.186851501464844\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.20201573427766562, Generator Loss: 4.156253814697266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.16859701834619045, Generator Loss: 4.252895832061768\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.20525594428181648, Generator Loss: 4.206576347351074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.19859618972986937, Generator Loss: 4.29945707321167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.16673356154933572, Generator Loss: 4.263482570648193\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.16061604674905539, Generator Loss: 4.214293479919434\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.1802353486418724, Generator Loss: 4.215639114379883\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.15546233393251896, Generator Loss: 4.26956844329834\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.15985463932156563, Generator Loss: 4.345525741577148\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.17623667605221272, Generator Loss: 4.323861122131348\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.15691971592605114, Generator Loss: 4.285146713256836\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.18916231021285057, Generator Loss: 4.237343788146973\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.17359301261603832, Generator Loss: 4.298865795135498\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.1522351442836225, Generator Loss: 4.336499214172363\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.15910976845771074, Generator Loss: 4.398416996002197\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.17293917294591665, Generator Loss: 4.309513092041016\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.14932192862033844, Generator Loss: 4.391218185424805\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.16110279597342014, Generator Loss: 4.311657905578613\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.1574135646224022, Generator Loss: 4.37238883972168\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.14142074342817068, Generator Loss: 4.383790969848633\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.1335533857345581, Generator Loss: 4.311856746673584\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.14342642249539495, Generator Loss: 4.332786560058594\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.1617983728647232, Generator Loss: 4.3346452713012695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.12731292191892862, Generator Loss: 4.326512336730957\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.14103160426020622, Generator Loss: 4.301719665527344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.13871149951592088, Generator Loss: 4.400547027587891\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.1194217735901475, Generator Loss: 4.433524131774902\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.1132616400718689, Generator Loss: 4.383833885192871\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.1568272914737463, Generator Loss: 4.387844085693359\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.12506804149597883, Generator Loss: 4.500513076782227\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.1360406936146319, Generator Loss: 4.425721168518066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.11916233133524656, Generator Loss: 4.432917594909668\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.1148221306502819, Generator Loss: 4.374508857727051\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.12334617227315903, Generator Loss: 4.432120323181152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.1520630018785596, Generator Loss: 4.422720909118652\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.1057990025728941, Generator Loss: 4.509525299072266\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.1115208794362843, Generator Loss: 4.328648567199707\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.11838302575051785, Generator Loss: 4.366374969482422\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.11502514965832233, Generator Loss: 4.284327507019043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.10291146393865347, Generator Loss: 4.377696990966797\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.12730352766811848, Generator Loss: 4.333987712860107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.10684328200295568, Generator Loss: 4.461595058441162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.10641052480787039, Generator Loss: 4.383119583129883\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.09083605511114001, Generator Loss: 4.459456920623779\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.12249486148357391, Generator Loss: 4.374436378479004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.11837986763566732, Generator Loss: 4.434887886047363\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.1125351544469595, Generator Loss: 4.331219673156738\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.09389518015086651, Generator Loss: 4.498410701751709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 activation, optimizer = adam\n",
        "\n",
        "output activation = sigmoid"
      ],
      "metadata": {
        "id": "8Gd9qdm71nl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## relu"
      ],
      "metadata": {
        "id": "Ki8FkNpn39kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXjN4AP33Efs",
        "outputId": "1ef0db19-ade0-4c64-c347-5748714d07e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.8483355045318604, Generator Loss: 0.4371866285800934\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6103552430868149, Generator Loss: 0.6390867233276367\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.5041152387857437, Generator Loss: 0.8884485960006714\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.40610338747501373, Generator Loss: 1.1705973148345947\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.3498876243829727, Generator Loss: 1.4392814636230469\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.27148105204105377, Generator Loss: 1.7357869148254395\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.2224211022257805, Generator Loss: 1.996477723121643\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.22777918726205826, Generator Loss: 2.242204189300537\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.21985851600766182, Generator Loss: 2.477940559387207\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.1563267931342125, Generator Loss: 2.6820802688598633\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.1455080807209015, Generator Loss: 2.856509208679199\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.2002444602549076, Generator Loss: 3.0021042823791504\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.14212104864418507, Generator Loss: 3.1354312896728516\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.17090022191405296, Generator Loss: 3.2421629428863525\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.13906751945614815, Generator Loss: 3.350731372833252\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.16098817996680737, Generator Loss: 3.4145545959472656\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.17857175692915916, Generator Loss: 3.484363555908203\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.16796515509486198, Generator Loss: 3.5202889442443848\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.16551749128848314, Generator Loss: 3.572443962097168\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.13716505095362663, Generator Loss: 3.621124267578125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.13292180560529232, Generator Loss: 3.646043300628662\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.1652127094566822, Generator Loss: 3.675675392150879\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.12390390690416098, Generator Loss: 3.6753897666931152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.15901285037398338, Generator Loss: 3.6877121925354004\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.14365206006914377, Generator Loss: 3.6904027462005615\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.13404832687228918, Generator Loss: 3.688176155090332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.14458321873098612, Generator Loss: 3.7231602668762207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.15010832250118256, Generator Loss: 3.693422317504883\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.12408312223851681, Generator Loss: 3.696584701538086\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.12842763494700193, Generator Loss: 3.654090404510498\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.11032625008374453, Generator Loss: 3.688185691833496\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.13282062020152807, Generator Loss: 3.712087869644165\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.10323003679513931, Generator Loss: 3.675138473510742\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.13454086892306805, Generator Loss: 3.681443214416504\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.11850566323846579, Generator Loss: 3.6877071857452393\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.1392288524657488, Generator Loss: 3.710860252380371\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.12097860313951969, Generator Loss: 3.7744486331939697\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.1337079806253314, Generator Loss: 3.662769317626953\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.11971474718302488, Generator Loss: 3.6978707313537598\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.12030085269361734, Generator Loss: 3.6790170669555664\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.11731169745326042, Generator Loss: 3.6948797702789307\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.10408838093280792, Generator Loss: 3.68943452835083\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.10989228263497353, Generator Loss: 3.6981043815612793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.08975378796458244, Generator Loss: 3.67413067817688\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.09785430319607258, Generator Loss: 3.6825380325317383\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.11511306185275316, Generator Loss: 3.6920981407165527\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.10335313156247139, Generator Loss: 3.7554731369018555\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.11610162816941738, Generator Loss: 3.7149133682250977\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.08948129415512085, Generator Loss: 3.7404584884643555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.1096525127068162, Generator Loss: 3.690584182739258\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.11046099849045277, Generator Loss: 3.763538360595703\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.0982478354126215, Generator Loss: 3.802725315093994\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.09093599580228329, Generator Loss: 3.7484757900238037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.09349639527499676, Generator Loss: 3.7410449981689453\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.08664297498762608, Generator Loss: 3.743344306945801\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.10557541996240616, Generator Loss: 3.7518467903137207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.10232272185385227, Generator Loss: 3.7929701805114746\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.08136654831469059, Generator Loss: 3.799663543701172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.08965540118515491, Generator Loss: 3.7512567043304443\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.08378088474273682, Generator Loss: 3.7879512310028076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.07816111017018557, Generator Loss: 3.809485912322998\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.09972708392888308, Generator Loss: 3.7328927516937256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.07747741509228945, Generator Loss: 3.7566308975219727\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.09021972678601742, Generator Loss: 3.8343963623046875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.08338815253227949, Generator Loss: 3.7845160961151123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.08856102172285318, Generator Loss: 3.7919559478759766\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.0795338898897171, Generator Loss: 3.8142266273498535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.07419895566999912, Generator Loss: 3.7978692054748535\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.08662976417690516, Generator Loss: 3.7960119247436523\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.0806112103164196, Generator Loss: 3.828488826751709\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.0724254883825779, Generator Loss: 3.8921146392822266\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.07489057630300522, Generator Loss: 3.79941987991333\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.07891223207116127, Generator Loss: 3.8613646030426025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.08087399415671825, Generator Loss: 3.7737934589385986\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.0741830412298441, Generator Loss: 3.867722988128662\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.07858501374721527, Generator Loss: 3.7854363918304443\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.07298330031335354, Generator Loss: 3.8898627758026123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.06903944723308086, Generator Loss: 3.8409056663513184\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.08144833892583847, Generator Loss: 3.8114781379699707\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.07609767094254494, Generator Loss: 3.8558437824249268\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.05710525065660477, Generator Loss: 3.803182601928711\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.07567530032247305, Generator Loss: 3.8421404361724854\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.07361177634447813, Generator Loss: 3.834200382232666\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.07704457174986601, Generator Loss: 3.8811464309692383\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.07577495835721493, Generator Loss: 3.7811455726623535\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.057075006887316704, Generator Loss: 3.8817684650421143\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.07327292114496231, Generator Loss: 3.8419361114501953\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.07497823052108288, Generator Loss: 3.832883834838867\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.07143175695091486, Generator Loss: 3.900385856628418\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.06461642496287823, Generator Loss: 3.872910976409912\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.05676298029720783, Generator Loss: 3.8826541900634766\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.0661865845322609, Generator Loss: 3.8364439010620117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.06312783434987068, Generator Loss: 3.8462975025177\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.06961068324744701, Generator Loss: 3.876972198486328\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.05629762168973684, Generator Loss: 3.995415687561035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.06129591818898916, Generator Loss: 3.965494155883789\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.0686059333384037, Generator Loss: 3.831881046295166\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.05716566927731037, Generator Loss: 4.017285346984863\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.06215940602123737, Generator Loss: 4.004554271697998\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.06684121955186129, Generator Loss: 3.91917085647583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeakyReLU"
      ],
      "metadata": {
        "id": "eTGk57hY4Qrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='LeakyReLU'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='LeakyReLU'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eny8FIaH5VIC",
        "outputId": "5cc9bbd6-5bbb-405d-f3bf-01e8d8cf5502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.6666022539138794, Generator Loss: 1.1098394393920898\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.5471976846456528, Generator Loss: 1.7239251136779785\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.41529730707407, Generator Loss: 2.395282506942749\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.40821099281311035, Generator Loss: 2.9738125801086426\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.39681243523955345, Generator Loss: 3.49904203414917\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.37849222123622894, Generator Loss: 3.885695695877075\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.4418186154216528, Generator Loss: 4.23897123336792\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.4259821833111346, Generator Loss: 4.47288703918457\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.354196107480675, Generator Loss: 4.6678266525268555\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.37153281923383474, Generator Loss: 4.8388872146606445\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.3528952058404684, Generator Loss: 4.953266143798828\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.3597838249988854, Generator Loss: 5.032313346862793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.40918982797302306, Generator Loss: 5.130373954772949\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.41860270756296813, Generator Loss: 5.163301467895508\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.3417302342131734, Generator Loss: 5.156277656555176\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.31921459920704365, Generator Loss: 5.187480449676514\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.3141507054679096, Generator Loss: 5.178008556365967\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.29106527706608176, Generator Loss: 5.171898365020752\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.3317130815703422, Generator Loss: 5.146636962890625\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.3442426547408104, Generator Loss: 5.151038646697998\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.3848136616870761, Generator Loss: 5.143866539001465\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.28428236045874655, Generator Loss: 5.063101768493652\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.31366263749077916, Generator Loss: 5.0663557052612305\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.3042816845700145, Generator Loss: 5.0222086906433105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.29855574760586023, Generator Loss: 4.983887672424316\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.3078909576870501, Generator Loss: 4.9597272872924805\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.3317819223739207, Generator Loss: 4.916566848754883\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.3338872501626611, Generator Loss: 4.834028244018555\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.29343034187331796, Generator Loss: 4.834197044372559\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.29874193482100964, Generator Loss: 4.839541912078857\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.288243664894253, Generator Loss: 4.776437759399414\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.34827084047719836, Generator Loss: 4.7689924240112305\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.2934576664119959, Generator Loss: 4.7244062423706055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.2855888642370701, Generator Loss: 4.69957971572876\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.2937519233673811, Generator Loss: 4.65799617767334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.28633986227214336, Generator Loss: 4.6769819259643555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.2531191580928862, Generator Loss: 4.603099822998047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.3021764000877738, Generator Loss: 4.600929260253906\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.27404822781682014, Generator Loss: 4.544368743896484\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.23600819101557136, Generator Loss: 4.580686092376709\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.2348487200215459, Generator Loss: 4.522722244262695\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.2693244097754359, Generator Loss: 4.565913200378418\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.2620701910927892, Generator Loss: 4.543558120727539\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.2534433724358678, Generator Loss: 4.472373008728027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.26425784919410944, Generator Loss: 4.502091884613037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.2717934800311923, Generator Loss: 4.578969955444336\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.26295199850574136, Generator Loss: 4.547610282897949\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.22010616306215525, Generator Loss: 4.536195278167725\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.2267655897885561, Generator Loss: 4.381778240203857\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.196396563667804, Generator Loss: 4.496012210845947\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.21110948780551553, Generator Loss: 4.446043968200684\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.20436245668679476, Generator Loss: 4.5672197341918945\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.19371312111616135, Generator Loss: 4.535277843475342\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.2615772569552064, Generator Loss: 4.45424222946167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.20829605776816607, Generator Loss: 4.470808506011963\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.21411981200799346, Generator Loss: 4.566372871398926\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.2213771427050233, Generator Loss: 4.499514579772949\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.22294013667851686, Generator Loss: 4.5401105880737305\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.1941223992034793, Generator Loss: 4.6390180587768555\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.21612722892314196, Generator Loss: 4.53812837600708\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.21830546529963613, Generator Loss: 4.517154693603516\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.20246563665568829, Generator Loss: 4.390978813171387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.17758404416963458, Generator Loss: 4.571665287017822\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.2228755783289671, Generator Loss: 4.533271789550781\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.22121463529765606, Generator Loss: 4.538694381713867\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.1648087501525879, Generator Loss: 4.501440048217773\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.19187698187306523, Generator Loss: 4.510970592498779\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.21825411263853312, Generator Loss: 4.619014739990234\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.21070543816313148, Generator Loss: 4.607003211975098\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.16830083262175322, Generator Loss: 4.517538547515869\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.20449565816670656, Generator Loss: 4.470664978027344\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.23476777272298932, Generator Loss: 4.608016490936279\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.21137266606092453, Generator Loss: 4.557092666625977\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.1842753211967647, Generator Loss: 4.545015811920166\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.19095529429614544, Generator Loss: 4.548717498779297\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.17321824841201305, Generator Loss: 4.518649578094482\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.16066437028348446, Generator Loss: 4.429313659667969\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.17773019336163998, Generator Loss: 4.4416961669921875\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.19155027344822884, Generator Loss: 4.51739501953125\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.13679998321458697, Generator Loss: 4.491125583648682\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.15976897673681378, Generator Loss: 4.458235740661621\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.17898972425609827, Generator Loss: 4.495185852050781\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.2030621049925685, Generator Loss: 4.6632232666015625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.14913475699722767, Generator Loss: 4.651102066040039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.163958088029176, Generator Loss: 4.588270664215088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.14655156712979078, Generator Loss: 4.363468170166016\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.1604681797325611, Generator Loss: 4.578782558441162\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.16876511089503765, Generator Loss: 4.60012149810791\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.12966675776988268, Generator Loss: 4.504363059997559\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.20143418945372105, Generator Loss: 4.572269439697266\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.1617694878950715, Generator Loss: 4.513517379760742\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.14796078903600574, Generator Loss: 4.584203243255615\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.14421753026545048, Generator Loss: 4.546679496765137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.13970014918595552, Generator Loss: 4.689122200012207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.13210290111601353, Generator Loss: 4.684999465942383\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.1399244675412774, Generator Loss: 4.61842155456543\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.139784284401685, Generator Loss: 4.672262191772461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.1265097032301128, Generator Loss: 4.662247180938721\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.1542816418223083, Generator Loss: 4.584888458251953\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.13472962519153953, Generator Loss: 4.7469282150268555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## elu"
      ],
      "metadata": {
        "id": "Wchl28pH4R9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='elu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='elu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqwgK9zz4TQn",
        "outputId": "22d519d2-beb0-49c1-fd95-3bed7338b591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.9392116665840149, Generator Loss: 0.6346926689147949\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6651347875595093, Generator Loss: 1.2459287643432617\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.4726167395710945, Generator Loss: 1.9961163997650146\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.4339911565184593, Generator Loss: 2.743772029876709\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.3639991991221905, Generator Loss: 3.4275054931640625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.32620599679648876, Generator Loss: 3.977827310562134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.3685890920460224, Generator Loss: 4.45877742767334\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.3581689028069377, Generator Loss: 4.797508239746094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.31740451510995626, Generator Loss: 5.115353107452393\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.3842156429309398, Generator Loss: 5.349908828735352\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.3370374087244272, Generator Loss: 5.527751445770264\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.32747106335591525, Generator Loss: 5.6697998046875\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.3247517894487828, Generator Loss: 5.783550262451172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.3847102972213179, Generator Loss: 5.8849592208862305\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.2897339495830238, Generator Loss: 5.984092712402344\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.45364018715918064, Generator Loss: 5.9998250007629395\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.2868662748951465, Generator Loss: 6.060018539428711\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.29719889408443123, Generator Loss: 6.082773208618164\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.3275423040613532, Generator Loss: 6.080118179321289\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.3330464177997783, Generator Loss: 6.0854291915893555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.39271852921228856, Generator Loss: 6.039131164550781\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.30381471780128777, Generator Loss: 6.076396942138672\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.26680675137322396, Generator Loss: 6.04754638671875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.2741003737319261, Generator Loss: 6.015701770782471\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.32288116915151477, Generator Loss: 5.98635196685791\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.3088169291149825, Generator Loss: 5.950220584869385\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.32987303123809397, Generator Loss: 5.9437174797058105\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.254801262402907, Generator Loss: 5.945976257324219\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.3209303899202496, Generator Loss: 5.88094425201416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.30104640987701714, Generator Loss: 5.825189113616943\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.28271291055716574, Generator Loss: 5.829592704772949\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.27148297242820263, Generator Loss: 5.788508415222168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.2440734209958464, Generator Loss: 5.757667541503906\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.2980446678120643, Generator Loss: 5.706123352050781\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.3450565797975287, Generator Loss: 5.68319034576416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.25904377340339124, Generator Loss: 5.663045883178711\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.26204806892201304, Generator Loss: 5.609344482421875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.2719037744682282, Generator Loss: 5.638223171234131\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.2676742149051279, Generator Loss: 5.5471296310424805\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.2264344529248774, Generator Loss: 5.522458076477051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.2860206267796457, Generator Loss: 5.530638694763184\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.24197959946468472, Generator Loss: 5.546859264373779\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.32072548498399556, Generator Loss: 5.45774507522583\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.2779992399737239, Generator Loss: 5.372093200683594\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.29632960353046656, Generator Loss: 5.307753562927246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.29147426038980484, Generator Loss: 5.356783390045166\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.2854752750135958, Generator Loss: 5.243466377258301\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.2945296950638294, Generator Loss: 5.243281364440918\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.2659619168844074, Generator Loss: 5.300850868225098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.2658438920043409, Generator Loss: 5.217276573181152\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.23397374572232366, Generator Loss: 5.2693634033203125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.19849809422157705, Generator Loss: 5.159830093383789\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.2627844447270036, Generator Loss: 5.124255180358887\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.2028200221247971, Generator Loss: 5.070133209228516\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.23618586687371135, Generator Loss: 5.087419509887695\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.23557181283831596, Generator Loss: 5.110454082489014\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.21402108808979392, Generator Loss: 5.213075637817383\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.21249198075383902, Generator Loss: 5.1814680099487305\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.2498765925411135, Generator Loss: 5.11954402923584\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.19627926917746663, Generator Loss: 5.1357574462890625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.23874156875535846, Generator Loss: 5.193975448608398\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.16562830051407218, Generator Loss: 5.061898231506348\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.2568192835897207, Generator Loss: 5.111475944519043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.24035601690411568, Generator Loss: 5.1036696434021\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.22102999966591597, Generator Loss: 5.083312034606934\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.21716120652854443, Generator Loss: 5.05065393447876\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.24149756226688623, Generator Loss: 5.042854309082031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.20914800930768251, Generator Loss: 5.097026824951172\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.23665354400873184, Generator Loss: 4.962098121643066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.23285257164388895, Generator Loss: 4.921892166137695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.246327911503613, Generator Loss: 5.084712505340576\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.21251539885997772, Generator Loss: 4.91691255569458\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.21728849411010742, Generator Loss: 4.998369216918945\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.2011762191541493, Generator Loss: 5.040276527404785\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.19768873043358326, Generator Loss: 4.957551956176758\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.22857960499823093, Generator Loss: 4.9726080894470215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.19075151113793254, Generator Loss: 4.9390363693237305\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.21294406312517822, Generator Loss: 4.887881278991699\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.1785564236342907, Generator Loss: 5.021965980529785\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.18712315429002047, Generator Loss: 4.981816291809082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.21709432266652584, Generator Loss: 4.988804340362549\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.21408745041117072, Generator Loss: 5.014343738555908\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.19105303287506104, Generator Loss: 5.000258445739746\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.20676608267240226, Generator Loss: 4.910655975341797\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.22359839361160994, Generator Loss: 4.9637250900268555\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.18136139307171106, Generator Loss: 4.973374366760254\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.21740284375846386, Generator Loss: 4.932607173919678\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.19348040409386158, Generator Loss: 5.079765319824219\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.20528717571869493, Generator Loss: 5.045541286468506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.17773045459762216, Generator Loss: 4.985495090484619\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.1791384369134903, Generator Loss: 5.048035621643066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.20097922254353762, Generator Loss: 5.010593414306641\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.17635238775983453, Generator Loss: 4.9925007820129395\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.16393912909552455, Generator Loss: 4.969795227050781\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.18106510071083903, Generator Loss: 5.04936408996582\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.17265562806278467, Generator Loss: 4.998395919799805\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.18093892792239785, Generator Loss: 5.047615051269531\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.1636671330779791, Generator Loss: 5.12198543548584\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.2029425106011331, Generator Loss: 5.13131856918335\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.16725371964275837, Generator Loss: 5.000385284423828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PReLU"
      ],
      "metadata": {
        "id": "POOElKx64UXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='PReLU'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='PReLU'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WLhyvGY4VFr",
        "outputId": "96b6899f-a49c-494b-e78c-eff9cddf540c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.7371473014354706, Generator Loss: 1.2192940711975098\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6483373790979385, Generator Loss: 1.6305361986160278\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.6321543231606483, Generator Loss: 2.08355712890625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.5813784152269363, Generator Loss: 2.5080819129943848\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.49484626576304436, Generator Loss: 2.908904552459717\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.5099383257329464, Generator Loss: 3.2484307289123535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.4972410462796688, Generator Loss: 3.548252820968628\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.508908910676837, Generator Loss: 3.781175136566162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.49108501244336367, Generator Loss: 3.9675350189208984\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.4811062691733241, Generator Loss: 4.121315002441406\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.5538784377276897, Generator Loss: 4.230658531188965\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.486905497033149, Generator Loss: 4.316704273223877\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.44225017819553614, Generator Loss: 4.390230178833008\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.43227544613182545, Generator Loss: 4.453060626983643\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.46613228134810925, Generator Loss: 4.445132255554199\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.39330167323350906, Generator Loss: 4.472894191741943\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.464375127106905, Generator Loss: 4.514676570892334\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.5059908544644713, Generator Loss: 4.5029296875\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.4181268624961376, Generator Loss: 4.497981071472168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.3651072885841131, Generator Loss: 4.470455646514893\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.40913018491119146, Generator Loss: 4.483316421508789\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.43895523669198155, Generator Loss: 4.471976280212402\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.39147670194506645, Generator Loss: 4.484365463256836\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.4071818511001766, Generator Loss: 4.447622299194336\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.33551484253257513, Generator Loss: 4.393951416015625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.44332825392484665, Generator Loss: 4.365398406982422\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.4059249758720398, Generator Loss: 4.361241340637207\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.37241439986974, Generator Loss: 4.3220367431640625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.3379328418523073, Generator Loss: 4.293471813201904\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.4088758146390319, Generator Loss: 4.299820899963379\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.3685794174671173, Generator Loss: 4.260513782501221\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.35935688065364957, Generator Loss: 4.229455471038818\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.35764451138675213, Generator Loss: 4.218052864074707\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.3049632264301181, Generator Loss: 4.168583393096924\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.3007494565099478, Generator Loss: 4.148181915283203\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.3437862638384104, Generator Loss: 4.1122846603393555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.31733872927725315, Generator Loss: 4.1309099197387695\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.3636018242686987, Generator Loss: 4.132091522216797\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.312168026342988, Generator Loss: 4.090811729431152\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.31184225529432297, Generator Loss: 4.063260078430176\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.3400056380778551, Generator Loss: 4.047336101531982\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.22245766688138247, Generator Loss: 4.001277446746826\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.2934264224022627, Generator Loss: 4.015365123748779\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.2823870973661542, Generator Loss: 4.078446388244629\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.2766545843333006, Generator Loss: 4.027121543884277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.30373687855899334, Generator Loss: 4.0260491371154785\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.2814402235671878, Generator Loss: 3.9564895629882812\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.2328075785189867, Generator Loss: 4.032461166381836\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.2322868537157774, Generator Loss: 3.960845470428467\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.2296069785952568, Generator Loss: 3.9954299926757812\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.26120820082724094, Generator Loss: 4.07466983795166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.2381205279380083, Generator Loss: 4.058295726776123\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.24805547762662172, Generator Loss: 4.0103535652160645\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.3184278830885887, Generator Loss: 4.01317024230957\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.26956076454371214, Generator Loss: 4.04823112487793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.2527162954211235, Generator Loss: 4.002899169921875\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.2116332110017538, Generator Loss: 4.01052188873291\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.2635140512138605, Generator Loss: 4.04232120513916\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.25709898490458727, Generator Loss: 4.083827018737793\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.24103459622710943, Generator Loss: 4.036386966705322\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.21316618379205465, Generator Loss: 3.9968323707580566\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.18487544357776642, Generator Loss: 4.10905647277832\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.22779415734112263, Generator Loss: 4.109972953796387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.20820010732859373, Generator Loss: 4.083292484283447\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.1889459751546383, Generator Loss: 4.14254093170166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.2198051381856203, Generator Loss: 4.041228294372559\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.257900457829237, Generator Loss: 4.1035051345825195\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.21739941462874413, Generator Loss: 4.085424423217773\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.20188498683273792, Generator Loss: 4.122798442840576\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.1652580862864852, Generator Loss: 4.071660995483398\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.24181474559009075, Generator Loss: 4.009817123413086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.20451710000634193, Generator Loss: 4.132850646972656\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.1979229962453246, Generator Loss: 4.152438163757324\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.17760662268847227, Generator Loss: 4.162823677062988\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.18510607816278934, Generator Loss: 4.150632858276367\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.19142195954918861, Generator Loss: 4.124259948730469\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.16897863615304232, Generator Loss: 4.090271949768066\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.2022153176367283, Generator Loss: 4.17251443862915\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.16686217207461596, Generator Loss: 4.1990275382995605\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.15587202832102776, Generator Loss: 4.180294990539551\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.15507375728338957, Generator Loss: 4.124268531799316\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.1484718518331647, Generator Loss: 4.177987098693848\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.14111224561929703, Generator Loss: 4.262584686279297\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.1716115903109312, Generator Loss: 4.207645893096924\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.13937086798250675, Generator Loss: 4.223695755004883\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.1724272556602955, Generator Loss: 4.23052978515625\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.14082544576376677, Generator Loss: 4.198520660400391\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.13518034387379885, Generator Loss: 4.282806396484375\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.17287387885153294, Generator Loss: 4.247849941253662\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.138211234472692, Generator Loss: 4.297852993011475\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.16568466741591692, Generator Loss: 4.2645792961120605\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.1601850651204586, Generator Loss: 4.349864482879639\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.12685097567737103, Generator Loss: 4.175422668457031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.1307707317173481, Generator Loss: 4.227901458740234\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.12218577275052667, Generator Loss: 4.266708850860596\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.1441002544015646, Generator Loss: 4.228000640869141\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.15701541304588318, Generator Loss: 4.222724437713623\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.1634136689826846, Generator Loss: 4.254277229309082\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.12982190400362015, Generator Loss: 4.226174354553223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.1268306728452444, Generator Loss: 4.187979698181152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "BKMawSye4V04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='sigmoid'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='sigmoid'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HcxO4J04W-w",
        "outputId": "98dcc47b-4d7a-4392-9cb1-ffd564ef7387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.7191917151212692, Generator Loss: 1.1138420104980469\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6853619664907455, Generator Loss: 1.2956457138061523\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.6379567384719849, Generator Loss: 1.4926944971084595\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.5993589386343956, Generator Loss: 1.6947638988494873\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.5655164420604706, Generator Loss: 1.890343189239502\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.564853273332119, Generator Loss: 2.074108123779297\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.5680992603302002, Generator Loss: 2.246067523956299\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.524850782006979, Generator Loss: 2.4036202430725098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.5043890848755836, Generator Loss: 2.548149347305298\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.511800043284893, Generator Loss: 2.670224905014038\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.4934222474694252, Generator Loss: 2.775540590286255\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.4791343715041876, Generator Loss: 2.8696653842926025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.4802521523088217, Generator Loss: 2.9523816108703613\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.49015264958143234, Generator Loss: 3.022958278656006\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.4747162163257599, Generator Loss: 3.0823702812194824\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.45066333189606667, Generator Loss: 3.1329898834228516\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.45740363746881485, Generator Loss: 3.1774673461914062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.46228933334350586, Generator Loss: 3.2156858444213867\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.44696882367134094, Generator Loss: 3.244354724884033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.4556275084614754, Generator Loss: 3.272428035736084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.44051957689225674, Generator Loss: 3.2989282608032227\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.41757645830512047, Generator Loss: 3.3160934448242188\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.4002465233206749, Generator Loss: 3.33021879196167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.4373238869011402, Generator Loss: 3.3493731021881104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.40875999443233013, Generator Loss: 3.357537269592285\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.4147544540464878, Generator Loss: 3.365036725997925\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.40058551356196404, Generator Loss: 3.372182607650757\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.4054804090410471, Generator Loss: 3.375328302383423\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.4219555724412203, Generator Loss: 3.3747739791870117\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.3933994919061661, Generator Loss: 3.375732421875\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.3960538189858198, Generator Loss: 3.3796911239624023\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.4111418128013611, Generator Loss: 3.374927520751953\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.3921955917030573, Generator Loss: 3.368671417236328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.37168173491954803, Generator Loss: 3.3647713661193848\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.37003912776708603, Generator Loss: 3.365342378616333\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.3773782551288605, Generator Loss: 3.360058546066284\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.3660573158413172, Generator Loss: 3.352145195007324\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.3813900426030159, Generator Loss: 3.349299192428589\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.36127379909157753, Generator Loss: 3.339646816253662\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.36623368225991726, Generator Loss: 3.3367528915405273\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.3586460817605257, Generator Loss: 3.3297414779663086\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.34057194367051125, Generator Loss: 3.3316686153411865\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.3556950315833092, Generator Loss: 3.316833972930908\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.3469034880399704, Generator Loss: 3.324295997619629\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.3404332250356674, Generator Loss: 3.3156321048736572\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.320678286254406, Generator Loss: 3.3098573684692383\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.33504391089081764, Generator Loss: 3.304476261138916\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.3517800737172365, Generator Loss: 3.3011250495910645\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.3403511494398117, Generator Loss: 3.296013832092285\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.3221075162291527, Generator Loss: 3.291539192199707\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.34577078744769096, Generator Loss: 3.2871787548065186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.3137154243886471, Generator Loss: 3.2867798805236816\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.32098332792520523, Generator Loss: 3.277818441390991\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.32903988286852837, Generator Loss: 3.275700569152832\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.3082745186984539, Generator Loss: 3.2694666385650635\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.30883272737264633, Generator Loss: 3.2619709968566895\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.3160692695528269, Generator Loss: 3.260950803756714\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.30883853882551193, Generator Loss: 3.2477223873138428\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.30020472034811974, Generator Loss: 3.244354248046875\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.3089977353811264, Generator Loss: 3.2393596172332764\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.2724559474736452, Generator Loss: 3.2443323135375977\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.2716696262359619, Generator Loss: 3.246778964996338\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.26128485798835754, Generator Loss: 3.2512550354003906\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.2751648835837841, Generator Loss: 3.2428476810455322\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.2787135634571314, Generator Loss: 3.252941370010376\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.2755724899470806, Generator Loss: 3.2463111877441406\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.28212892450392246, Generator Loss: 3.2431750297546387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.28851813450455666, Generator Loss: 3.23513126373291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.2825773321092129, Generator Loss: 3.2377777099609375\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.2745568323880434, Generator Loss: 3.234879970550537\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.2696534488350153, Generator Loss: 3.2168431282043457\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.25702317990362644, Generator Loss: 3.2168402671813965\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.25715887174010277, Generator Loss: 3.21894907951355\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.2477420661598444, Generator Loss: 3.2133357524871826\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.2789067532867193, Generator Loss: 3.2115516662597656\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.2687118984758854, Generator Loss: 3.203083038330078\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.23973111249506474, Generator Loss: 3.1934170722961426\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.26167967543005943, Generator Loss: 3.190627098083496\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.2458544559776783, Generator Loss: 3.18471097946167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.25623540952801704, Generator Loss: 3.184382915496826\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.23514288291335106, Generator Loss: 3.157325029373169\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.23996285162866116, Generator Loss: 3.1645357608795166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.26136281713843346, Generator Loss: 3.1545863151550293\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.24955770932137966, Generator Loss: 3.141533613204956\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.24944954365491867, Generator Loss: 3.149610757827759\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.23072276636958122, Generator Loss: 3.137014865875244\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.24119642563164234, Generator Loss: 3.13480544090271\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.22472921013832092, Generator Loss: 3.128366470336914\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.22983060777187347, Generator Loss: 3.119936943054199\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.21319452300667763, Generator Loss: 3.1240077018737793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.23682523891329765, Generator Loss: 3.1077358722686768\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.21038944832980633, Generator Loss: 3.112147569656372\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.20916417427361012, Generator Loss: 3.089576005935669\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.23913750797510147, Generator Loss: 3.1034083366394043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.22241749614477158, Generator Loss: 3.098127841949463\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.22584988363087177, Generator Loss: 3.0905699729919434\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.18530311062932014, Generator Loss: 3.0829110145568848\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.20508291572332382, Generator Loss: 3.08903431892395\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.21635528281331062, Generator Loss: 3.0719525814056396\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.21077821403741837, Generator Loss: 3.062044620513916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tanh"
      ],
      "metadata": {
        "id": "NwCVjSrW4XsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='tanh'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='tanh'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoLUhdqy4YiO",
        "outputId": "84e19d29-495b-4fd4-f9fc-f6fa32d56680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.8165392279624939, Generator Loss: 0.8608134388923645\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6211243867874146, Generator Loss: 1.481255292892456\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.456589512526989, Generator Loss: 2.194389820098877\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.42766691371798515, Generator Loss: 2.8565773963928223\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.421856414526701, Generator Loss: 3.4424867630004883\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.4326293608173728, Generator Loss: 3.9297263622283936\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.4069856833666563, Generator Loss: 4.333117485046387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.4032826856710017, Generator Loss: 4.694492340087891\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.42707204446196556, Generator Loss: 4.937252521514893\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.39392597507685423, Generator Loss: 5.1588521003723145\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.40411776560358703, Generator Loss: 5.343183994293213\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.42193902703002095, Generator Loss: 5.485301971435547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.3780015470692888, Generator Loss: 5.603432655334473\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.4052210752852261, Generator Loss: 5.7163190841674805\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.40115817449986935, Generator Loss: 5.797539710998535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.43452489527408034, Generator Loss: 5.852932929992676\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.38931970414705575, Generator Loss: 5.9176025390625\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.3685761501546949, Generator Loss: 5.940019607543945\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.4107663902686909, Generator Loss: 5.958212852478027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.42758215754292905, Generator Loss: 5.980762481689453\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.4357790305512026, Generator Loss: 5.999514579772949\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.44686451833695173, Generator Loss: 6.02130126953125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.42897183168679476, Generator Loss: 6.024476051330566\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.3982044127769768, Generator Loss: 6.0317277908325195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.42151842021849006, Generator Loss: 6.033891201019287\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.4187974773813039, Generator Loss: 6.0262370109558105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.4165344792418182, Generator Loss: 6.030968189239502\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.40485850372351706, Generator Loss: 6.02552604675293\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.3648318873019889, Generator Loss: 6.019739627838135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.41227619256824255, Generator Loss: 6.019153118133545\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.39045268611516804, Generator Loss: 6.005788803100586\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.39897166704759, Generator Loss: 6.000918388366699\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.3338163828011602, Generator Loss: 5.982207775115967\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.3301010013092309, Generator Loss: 5.96601676940918\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.3953028339892626, Generator Loss: 5.968175888061523\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.37639285810291767, Generator Loss: 5.916358470916748\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.3390030302107334, Generator Loss: 5.92654275894165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.37375555955804884, Generator Loss: 5.90190315246582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.43081035220529884, Generator Loss: 5.913244247436523\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.40160797524731606, Generator Loss: 5.876662254333496\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.38018579222261906, Generator Loss: 5.865846633911133\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.4289581791963428, Generator Loss: 5.861298561096191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.3976096131373197, Generator Loss: 5.841773986816406\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.3744290506001562, Generator Loss: 5.8067169189453125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.4375143749639392, Generator Loss: 5.791106224060059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.39211631612852216, Generator Loss: 5.779440879821777\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.3503515643533319, Generator Loss: 5.756704330444336\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.3326566540636122, Generator Loss: 5.742880821228027\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.36371623910963535, Generator Loss: 5.740662574768066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.3414535825140774, Generator Loss: 5.712794303894043\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.37950860837008804, Generator Loss: 5.718772888183594\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.33554698911029845, Generator Loss: 5.699467182159424\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.3815976739861071, Generator Loss: 5.686841011047363\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.342042095027864, Generator Loss: 5.6858415603637695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.33402948873117566, Generator Loss: 5.646420478820801\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.4384482060559094, Generator Loss: 5.663656711578369\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.35999401728622615, Generator Loss: 5.6430816650390625\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.3444434246048331, Generator Loss: 5.648489952087402\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.37062958790920675, Generator Loss: 5.620954513549805\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.29870868765283376, Generator Loss: 5.608587265014648\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.37689114827662706, Generator Loss: 5.647280693054199\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.4020083157811314, Generator Loss: 5.595707893371582\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.4082165772560984, Generator Loss: 5.609742164611816\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.34519625769462436, Generator Loss: 5.629766464233398\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.3741431754315272, Generator Loss: 5.600029945373535\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.32166635850444436, Generator Loss: 5.606300354003906\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.3457963952096179, Generator Loss: 5.599725246429443\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.38458399940282106, Generator Loss: 5.615317344665527\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.39509783242829144, Generator Loss: 5.61643123626709\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.35708940657787025, Generator Loss: 5.587701797485352\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.36650884128175676, Generator Loss: 5.610114097595215\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.3911288996459916, Generator Loss: 5.595251083374023\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.3466465435922146, Generator Loss: 5.590261459350586\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.35844045295380056, Generator Loss: 5.563478469848633\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.3343538506887853, Generator Loss: 5.582225799560547\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.3587158037116751, Generator Loss: 5.545825958251953\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.32347602280788124, Generator Loss: 5.529181957244873\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.34995624190196395, Generator Loss: 5.5629754066467285\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.39074887055903673, Generator Loss: 5.577151775360107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.34917028341442347, Generator Loss: 5.531968116760254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.3373801656998694, Generator Loss: 5.551311016082764\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.35411671083420515, Generator Loss: 5.529117584228516\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.351489613763988, Generator Loss: 5.524297714233398\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.34903094498440623, Generator Loss: 5.520053863525391\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.3327274147886783, Generator Loss: 5.535282135009766\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.35520697105675936, Generator Loss: 5.532724380493164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.36906042601913214, Generator Loss: 5.558048248291016\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.3506922824308276, Generator Loss: 5.533140659332275\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.3106950391083956, Generator Loss: 5.522246360778809\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.3661976451985538, Generator Loss: 5.555011749267578\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.3722344492562115, Generator Loss: 5.5171661376953125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.3049409743398428, Generator Loss: 5.552540302276611\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.34790260437875986, Generator Loss: 5.543486595153809\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.3300523515790701, Generator Loss: 5.586130142211914\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.30915500642731786, Generator Loss: 5.553393363952637\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.3334030482219532, Generator Loss: 5.562520980834961\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.3312614025780931, Generator Loss: 5.574141502380371\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.35903487890027463, Generator Loss: 5.576620578765869\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.3201334022451192, Generator Loss: 5.560880661010742\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.35730579984374344, Generator Loss: 5.559596061706543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## softmax"
      ],
      "metadata": {
        "id": "llbuCfmp4ZaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='softmax'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='softmax'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sBKKt9e4aSF",
        "outputId": "4b7afe99-166b-48b7-bb8c-d7401335d253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.6929576694965363, Generator Loss: 0.6915794610977173\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6903967261314392, Generator Loss: 0.6962755918502808\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.6887102723121643, Generator Loss: 0.7010542154312134\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.6864204406738281, Generator Loss: 0.705707311630249\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.6848939657211304, Generator Loss: 0.7101559638977051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.6817993521690369, Generator Loss: 0.7143985033035278\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.6785003244876862, Generator Loss: 0.7184659242630005\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.678053081035614, Generator Loss: 0.7223540544509888\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.6741932034492493, Generator Loss: 0.7260814309120178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.6740716397762299, Generator Loss: 0.7296292185783386\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.6738434433937073, Generator Loss: 0.7329870462417603\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.6712123155593872, Generator Loss: 0.736158549785614\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.6694565415382385, Generator Loss: 0.7391415238380432\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.6685691475868225, Generator Loss: 0.7419464588165283\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.6682703495025635, Generator Loss: 0.7445687055587769\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.665093868970871, Generator Loss: 0.7470462322235107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.664516270160675, Generator Loss: 0.7493813633918762\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.6638557314872742, Generator Loss: 0.7515889406204224\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.6640594601631165, Generator Loss: 0.7536879777908325\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.6620307564735413, Generator Loss: 0.7556970119476318\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.6602097749710083, Generator Loss: 0.7576297521591187\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.6615778803825378, Generator Loss: 0.7594909071922302\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.6590194702148438, Generator Loss: 0.7613032460212708\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.6584341824054718, Generator Loss: 0.7630833387374878\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.6579394638538361, Generator Loss: 0.7648328542709351\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.656038761138916, Generator Loss: 0.7665700912475586\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.6552750766277313, Generator Loss: 0.7682943344116211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.655542641878128, Generator Loss: 0.7700121402740479\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.6549153923988342, Generator Loss: 0.7717155814170837\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.6537569165229797, Generator Loss: 0.7734096050262451\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.6521533131599426, Generator Loss: 0.7750900983810425\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.6519022583961487, Generator Loss: 0.7767455577850342\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.6501517593860626, Generator Loss: 0.778374433517456\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.6503893733024597, Generator Loss: 0.7799652814865112\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.6508279144763947, Generator Loss: 0.7815032601356506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.6491209864616394, Generator Loss: 0.7829846739768982\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.647219717502594, Generator Loss: 0.7843986749649048\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.6473714113235474, Generator Loss: 0.7857464551925659\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.6472987532615662, Generator Loss: 0.787026584148407\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.6457483172416687, Generator Loss: 0.7882366180419922\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.6448614597320557, Generator Loss: 0.7893815636634827\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.6445437371730804, Generator Loss: 0.7904677987098694\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.6446495652198792, Generator Loss: 0.7915056943893433\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.6449203789234161, Generator Loss: 0.7925001978874207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.6439384520053864, Generator Loss: 0.793463945388794\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.6429639458656311, Generator Loss: 0.794406533241272\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.6430315375328064, Generator Loss: 0.7953342199325562\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.6426296532154083, Generator Loss: 0.7962496876716614\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.642313152551651, Generator Loss: 0.7971590757369995\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.6403469443321228, Generator Loss: 0.7980643510818481\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.6406954526901245, Generator Loss: 0.798965334892273\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.6401620507240295, Generator Loss: 0.7998578548431396\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.6395973265171051, Generator Loss: 0.8007400035858154\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.6385863721370697, Generator Loss: 0.801604151725769\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.6398046612739563, Generator Loss: 0.8024436235427856\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.6387820541858673, Generator Loss: 0.803252100944519\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.6388198733329773, Generator Loss: 0.8040279150009155\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.6384257078170776, Generator Loss: 0.804767370223999\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.6378961801528931, Generator Loss: 0.8054707050323486\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.6372262537479401, Generator Loss: 0.8061362504959106\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.6368170976638794, Generator Loss: 0.8067628145217896\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.6371802985668182, Generator Loss: 0.8073540329933167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.6358780562877655, Generator Loss: 0.8079142570495605\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.6351779699325562, Generator Loss: 0.8084424734115601\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.6343061327934265, Generator Loss: 0.8089445233345032\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.6344420611858368, Generator Loss: 0.8094210624694824\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.6360679864883423, Generator Loss: 0.8098759651184082\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.6338578164577484, Generator Loss: 0.810312032699585\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.6345424354076385, Generator Loss: 0.810728907585144\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.6338168978691101, Generator Loss: 0.8111294507980347\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.6342392861843109, Generator Loss: 0.8115176558494568\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.6340422630310059, Generator Loss: 0.8118916749954224\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.6328440308570862, Generator Loss: 0.8122546672821045\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.6331750750541687, Generator Loss: 0.8126076459884644\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.6330070197582245, Generator Loss: 0.8129521608352661\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.633812814950943, Generator Loss: 0.8132883310317993\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.6314679682254791, Generator Loss: 0.8136175870895386\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.6324829757213593, Generator Loss: 0.8139394521713257\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.6327259838581085, Generator Loss: 0.8142549991607666\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.6333903670310974, Generator Loss: 0.814564049243927\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.6323941946029663, Generator Loss: 0.8148669004440308\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.6309406459331512, Generator Loss: 0.8151657581329346\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.6310708820819855, Generator Loss: 0.8154590129852295\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.6325041055679321, Generator Loss: 0.8157477378845215\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.6296270191669464, Generator Loss: 0.8160330653190613\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.629661351442337, Generator Loss: 0.8163141012191772\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.630210667848587, Generator Loss: 0.8165912628173828\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.6315056085586548, Generator Loss: 0.8168646693229675\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.630639374256134, Generator Loss: 0.8171345591545105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.6296400725841522, Generator Loss: 0.8174018859863281\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.630167543888092, Generator Loss: 0.8176658749580383\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.6310884356498718, Generator Loss: 0.8179269433021545\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.6294485330581665, Generator Loss: 0.8181858658790588\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.630043625831604, Generator Loss: 0.8184417486190796\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.6294541358947754, Generator Loss: 0.8186947107315063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.6280882358551025, Generator Loss: 0.8189455270767212\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.6281009018421173, Generator Loss: 0.8191945552825928\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.6269470453262329, Generator Loss: 0.8194416761398315\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.6293758153915405, Generator Loss: 0.8196859359741211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.6286753416061401, Generator Loss: 0.819927453994751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best activation function = relu.\n",
        "Epoch 100/100, Discriminator Loss: 0.06684121955186129, Generator Loss: 3.91917085647583 (?)"
      ],
      "metadata": {
        "id": "KOPgAtza4amJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best activation function: relu, 8 optimizer"
      ],
      "metadata": {
        "id": "sgBxkfge4d7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD"
      ],
      "metadata": {
        "id": "wug-fGLg4j1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=SGD(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=SGD(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nSVs4ki4idq",
        "outputId": "1e705f09-642c-4904-8921-d89cbf3a3705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.48816950619220734, Generator Loss: 1.1955674886703491\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.46098193526268005, Generator Loss: 1.1976029872894287\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.467398539185524, Generator Loss: 1.201136827468872\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.49841998517513275, Generator Loss: 1.226931095123291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.500644788146019, Generator Loss: 1.219269037246704\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.4449627995491028, Generator Loss: 1.2356300354003906\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.4500531852245331, Generator Loss: 1.2460296154022217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.3944842368364334, Generator Loss: 1.2596015930175781\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.4627000689506531, Generator Loss: 1.2640661001205444\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.45315995812416077, Generator Loss: 1.2640502452850342\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.4758210629224777, Generator Loss: 1.2863212823867798\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.4496440291404724, Generator Loss: 1.2952349185943604\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.43666940927505493, Generator Loss: 1.303983211517334\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.4244595170021057, Generator Loss: 1.3162473440170288\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.4064795821905136, Generator Loss: 1.322326421737671\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.41972920298576355, Generator Loss: 1.3277242183685303\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.35012437403202057, Generator Loss: 1.3315765857696533\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.4264122545719147, Generator Loss: 1.3344542980194092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.4416223615407944, Generator Loss: 1.3482226133346558\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.393136203289032, Generator Loss: 1.357203483581543\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.39260080456733704, Generator Loss: 1.36793053150177\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.38112059235572815, Generator Loss: 1.3650003671646118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.4097595512866974, Generator Loss: 1.3854265213012695\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.4106101542711258, Generator Loss: 1.3985297679901123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.4358409345149994, Generator Loss: 1.4001591205596924\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.45084211230278015, Generator Loss: 1.411218523979187\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.4100727438926697, Generator Loss: 1.4189401865005493\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.4404640942811966, Generator Loss: 1.4240448474884033\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.45377591252326965, Generator Loss: 1.4341037273406982\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.4268355071544647, Generator Loss: 1.433228850364685\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.37672625482082367, Generator Loss: 1.4563413858413696\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.40076328814029694, Generator Loss: 1.450343132019043\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.4433256685733795, Generator Loss: 1.4674203395843506\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.3910467177629471, Generator Loss: 1.4780696630477905\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.3689882755279541, Generator Loss: 1.4682661294937134\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.41872361302375793, Generator Loss: 1.4956555366516113\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.4067971110343933, Generator Loss: 1.4993467330932617\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.39954644441604614, Generator Loss: 1.498002290725708\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.4473108947277069, Generator Loss: 1.5190794467926025\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.3785273879766464, Generator Loss: 1.519819736480713\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.38832274824380875, Generator Loss: 1.5202997922897339\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.420095294713974, Generator Loss: 1.530634880065918\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.40983349084854126, Generator Loss: 1.5426738262176514\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.39932015538215637, Generator Loss: 1.53934645652771\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.36700712889432907, Generator Loss: 1.5517499446868896\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.40073007345199585, Generator Loss: 1.5626698732376099\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.3701082468032837, Generator Loss: 1.5591306686401367\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.3961368650197983, Generator Loss: 1.5573410987854004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.31663455069065094, Generator Loss: 1.5681005716323853\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.36665184795856476, Generator Loss: 1.5932083129882812\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.3623555228114128, Generator Loss: 1.594720721244812\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.4244363605976105, Generator Loss: 1.6097502708435059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.3811217322945595, Generator Loss: 1.6123430728912354\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.4428894594311714, Generator Loss: 1.612269639968872\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.37039704620838165, Generator Loss: 1.6036298274993896\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.38635142892599106, Generator Loss: 1.6215567588806152\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.35081370174884796, Generator Loss: 1.622822880744934\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.35833486914634705, Generator Loss: 1.6459956169128418\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.3578890413045883, Generator Loss: 1.6500773429870605\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.32748400419950485, Generator Loss: 1.6251325607299805\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.3545611500740051, Generator Loss: 1.6545472145080566\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.42886343598365784, Generator Loss: 1.666358470916748\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.35150181502103806, Generator Loss: 1.6559796333312988\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.35222429037094116, Generator Loss: 1.6836738586425781\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.34184420108795166, Generator Loss: 1.6832525730133057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.34138939529657364, Generator Loss: 1.6918013095855713\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.37248604744672775, Generator Loss: 1.6848578453063965\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.3194207027554512, Generator Loss: 1.7077217102050781\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.3457622230052948, Generator Loss: 1.7112199068069458\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.34852609038352966, Generator Loss: 1.7101354598999023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.3562566339969635, Generator Loss: 1.7231667041778564\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.3810204938054085, Generator Loss: 1.7232997417449951\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.38695020973682404, Generator Loss: 1.728226900100708\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.3517713099718094, Generator Loss: 1.7335071563720703\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.3928535133600235, Generator Loss: 1.7462713718414307\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.3152770772576332, Generator Loss: 1.7475643157958984\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.41692396998405457, Generator Loss: 1.760770320892334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.34962835907936096, Generator Loss: 1.7527227401733398\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.3971998915076256, Generator Loss: 1.7718377113342285\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.3386162370443344, Generator Loss: 1.7656793594360352\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.35908369719982147, Generator Loss: 1.7777546644210815\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.3429233878850937, Generator Loss: 1.7803882360458374\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.3618125170469284, Generator Loss: 1.7776949405670166\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.31251709908246994, Generator Loss: 1.7894940376281738\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.3463044911623001, Generator Loss: 1.7981171607971191\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.35397814214229584, Generator Loss: 1.7956565618515015\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.34157994389533997, Generator Loss: 1.8015836477279663\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.2890669256448746, Generator Loss: 1.8082506656646729\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.33982209861278534, Generator Loss: 1.8179837465286255\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.288927398622036, Generator Loss: 1.8168805837631226\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.3340343236923218, Generator Loss: 1.8340036869049072\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.35369399189949036, Generator Loss: 1.821104884147644\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.3069770336151123, Generator Loss: 1.834547996520996\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.34754278510808945, Generator Loss: 1.8352832794189453\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.3479773998260498, Generator Loss: 1.8433395624160767\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.32869645208120346, Generator Loss: 1.8407542705535889\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.29994362592697144, Generator Loss: 1.8543826341629028\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.3605518341064453, Generator Loss: 1.8686504364013672\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.3124988526105881, Generator Loss: 1.8659594058990479\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.32278117537498474, Generator Loss: 1.8683912754058838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD with Momentum"
      ],
      "metadata": {
        "id": "liJjph2d4ktK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=SGD(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=SGD(learning_rate=0.0002, momentum=0.9), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNRw4H9r4k-Y",
        "outputId": "dff42c59-27ca-41a9-ab9f-1bd313437a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.9617482125759125, Generator Loss: 0.4084407091140747\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.9347191751003265, Generator Loss: 0.41926395893096924\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.9230595827102661, Generator Loss: 0.4281107783317566\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.8794839978218079, Generator Loss: 0.4376775622367859\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.8949667513370514, Generator Loss: 0.43996021151542664\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.9068942070007324, Generator Loss: 0.4532725214958191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.8473237752914429, Generator Loss: 0.4658412039279938\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.8045857846736908, Generator Loss: 0.4709840416908264\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.8584492802619934, Generator Loss: 0.47478947043418884\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.8033510446548462, Generator Loss: 0.4814716577529907\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.8694964349269867, Generator Loss: 0.493887722492218\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.8152492642402649, Generator Loss: 0.49996238946914673\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.8608644902706146, Generator Loss: 0.5067177414894104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.7960778474807739, Generator Loss: 0.5163350701332092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.833456963300705, Generator Loss: 0.5309323072433472\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.8010234236717224, Generator Loss: 0.5358917713165283\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.8624111115932465, Generator Loss: 0.5436702966690063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.7798360288143158, Generator Loss: 0.5527908802032471\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.766616702079773, Generator Loss: 0.5594667196273804\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.7953424453735352, Generator Loss: 0.5655984878540039\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.8108164370059967, Generator Loss: 0.5754213929176331\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.728266716003418, Generator Loss: 0.5877104997634888\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.7849259972572327, Generator Loss: 0.59159916639328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.7023954093456268, Generator Loss: 0.6065223217010498\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.747481644153595, Generator Loss: 0.6054673194885254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.7910604476928711, Generator Loss: 0.6193611025810242\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.7524144649505615, Generator Loss: 0.6308120489120483\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.7470484673976898, Generator Loss: 0.6310329437255859\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.7046962678432465, Generator Loss: 0.6378275156021118\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.7253274321556091, Generator Loss: 0.6592346429824829\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.7035240232944489, Generator Loss: 0.6573339700698853\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.7556041181087494, Generator Loss: 0.6678810119628906\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.7157562375068665, Generator Loss: 0.6737896800041199\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.7123366594314575, Generator Loss: 0.6860032081604004\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.6995669603347778, Generator Loss: 0.6913951635360718\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.682944267988205, Generator Loss: 0.698842465877533\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.749918669462204, Generator Loss: 0.7071407437324524\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.683249294757843, Generator Loss: 0.7169938087463379\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.6616144180297852, Generator Loss: 0.7288124561309814\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.7116930484771729, Generator Loss: 0.7356434464454651\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.6360947489738464, Generator Loss: 0.7466354370117188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.6780463457107544, Generator Loss: 0.7439491152763367\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.647083580493927, Generator Loss: 0.7598746418952942\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.7380131185054779, Generator Loss: 0.7669928669929504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.6114649474620819, Generator Loss: 0.7695197463035583\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.6244441270828247, Generator Loss: 0.7838935852050781\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.690056711435318, Generator Loss: 0.7818045616149902\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.7273222804069519, Generator Loss: 0.788722813129425\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.6466953158378601, Generator Loss: 0.7915908694267273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.6352993845939636, Generator Loss: 0.8091448545455933\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.6501498520374298, Generator Loss: 0.823077917098999\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.5831603407859802, Generator Loss: 0.8273648023605347\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.6377502083778381, Generator Loss: 0.8321052193641663\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.5428994596004486, Generator Loss: 0.8366128206253052\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.5892646908760071, Generator Loss: 0.8407953977584839\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.6339073479175568, Generator Loss: 0.8529025912284851\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.5862244963645935, Generator Loss: 0.8555898666381836\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.5925970375537872, Generator Loss: 0.8724573850631714\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.5942224264144897, Generator Loss: 0.8764004707336426\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.5718002021312714, Generator Loss: 0.8781850934028625\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.5967302620410919, Generator Loss: 0.8865475654602051\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.582063764333725, Generator Loss: 0.8959224820137024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.6522409319877625, Generator Loss: 0.9025164842605591\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.596786379814148, Generator Loss: 0.9067354202270508\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.5761135518550873, Generator Loss: 0.9187859296798706\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.6043621003627777, Generator Loss: 0.9194610118865967\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.5993339121341705, Generator Loss: 0.9256207942962646\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.5828427076339722, Generator Loss: 0.9345182776451111\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.6843649446964264, Generator Loss: 0.9459559917449951\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.6461421996355057, Generator Loss: 0.9518094658851624\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.553034096956253, Generator Loss: 0.9507367014884949\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.5125973522663116, Generator Loss: 0.9625387191772461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.5268542468547821, Generator Loss: 0.9676694273948669\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.5601515471935272, Generator Loss: 0.9727524518966675\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.5841704607009888, Generator Loss: 0.9721060991287231\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.5782997608184814, Generator Loss: 0.995197057723999\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.5690239369869232, Generator Loss: 0.9942074418067932\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.5389661639928818, Generator Loss: 0.9956414699554443\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.5246489644050598, Generator Loss: 1.008695363998413\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.5657615065574646, Generator Loss: 1.0090327262878418\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.4735567271709442, Generator Loss: 1.0297768115997314\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.5636681914329529, Generator Loss: 1.023646593093872\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.5751132816076279, Generator Loss: 1.0266181230545044\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.5921970009803772, Generator Loss: 1.040005087852478\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.5771291255950928, Generator Loss: 1.0427000522613525\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.6002252399921417, Generator Loss: 1.0532022714614868\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.5064331591129303, Generator Loss: 1.0552189350128174\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.5087204426527023, Generator Loss: 1.0652650594711304\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.5234064012765884, Generator Loss: 1.0686607360839844\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.5273380428552628, Generator Loss: 1.0780023336410522\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.5812720060348511, Generator Loss: 1.0851857662200928\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.5052732676267624, Generator Loss: 1.0877814292907715\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.5444753915071487, Generator Loss: 1.0843946933746338\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.5460451692342758, Generator Loss: 1.1008391380310059\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.5708071291446686, Generator Loss: 1.11001455783844\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.496200293302536, Generator Loss: 1.1092064380645752\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.533840149641037, Generator Loss: 1.1229546070098877\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.5112475454807281, Generator Loss: 1.1229075193405151\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.5307731628417969, Generator Loss: 1.130303144454956\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.5061271786689758, Generator Loss: 1.1365671157836914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "wke7lrhZ4lRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=RMSprop(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=RMSprop(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRNyAxUw4nbO",
        "outputId": "7efb6581-e8ba-46cb-e75e-83a30f527192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.6673113703727722, Generator Loss: 2.0603761672973633\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.40881116688251495, Generator Loss: 2.4071719646453857\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.43188953772187233, Generator Loss: 2.6917238235473633\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.4104255586862564, Generator Loss: 2.8758630752563477\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.39298442006111145, Generator Loss: 3.0295894145965576\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.346389502286911, Generator Loss: 3.191779613494873\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.3939501829445362, Generator Loss: 3.275360584259033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.33909672126173973, Generator Loss: 3.3968803882598877\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.34783778712153435, Generator Loss: 3.484118938446045\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.34661025553941727, Generator Loss: 3.5375895500183105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.385822044685483, Generator Loss: 3.6865925788879395\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.29947807639837265, Generator Loss: 3.7430334091186523\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.36429070867598057, Generator Loss: 3.8074982166290283\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.3320385254919529, Generator Loss: 3.843310832977295\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.30015121027827263, Generator Loss: 3.8704991340637207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.3612652765586972, Generator Loss: 3.934025764465332\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.2918563112616539, Generator Loss: 4.038653373718262\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.3115333579480648, Generator Loss: 4.018989562988281\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.26734559517353773, Generator Loss: 4.055225849151611\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.2603113315999508, Generator Loss: 4.089170932769775\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.33140568993985653, Generator Loss: 4.117624282836914\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.2697799280285835, Generator Loss: 4.160823822021484\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.26820075791329145, Generator Loss: 4.20133113861084\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.25404948368668556, Generator Loss: 4.280978202819824\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.2975644897669554, Generator Loss: 4.246201992034912\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.19624141231179237, Generator Loss: 4.304342746734619\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.2860818123444915, Generator Loss: 4.3751654624938965\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.24216082319617271, Generator Loss: 4.318138122558594\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.24725752091035247, Generator Loss: 4.433105945587158\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.2214848678559065, Generator Loss: 4.422536373138428\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.25044701155275106, Generator Loss: 4.492440223693848\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.21900727739557624, Generator Loss: 4.496946811676025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.2272653803229332, Generator Loss: 4.513526916503906\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.2667533755302429, Generator Loss: 4.467581748962402\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.2085742107592523, Generator Loss: 4.520414352416992\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.21469339728355408, Generator Loss: 4.54461669921875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.2096081213094294, Generator Loss: 4.582502841949463\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.1942949891090393, Generator Loss: 4.5458269119262695\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.2089085062034428, Generator Loss: 4.539684295654297\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.16646787617355585, Generator Loss: 4.663211822509766\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.2047472158446908, Generator Loss: 4.636553764343262\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.23665143828839064, Generator Loss: 4.620051383972168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.19314995594322681, Generator Loss: 4.6107707023620605\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.2091614305973053, Generator Loss: 4.611204147338867\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.16858918778598309, Generator Loss: 4.563945770263672\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.1777118849568069, Generator Loss: 4.609879493713379\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.2004714822396636, Generator Loss: 4.705092906951904\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.15439555142074823, Generator Loss: 4.71417236328125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.16140574542805552, Generator Loss: 4.669484615325928\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.18164391303434968, Generator Loss: 4.668976306915283\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.16392548428848386, Generator Loss: 4.699868202209473\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.15120750851929188, Generator Loss: 4.78560733795166\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.12550731841474771, Generator Loss: 4.766387939453125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.13573845103383064, Generator Loss: 4.7603936195373535\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.14560845494270325, Generator Loss: 4.79316520690918\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.15448018116876483, Generator Loss: 4.719871997833252\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.13341784663498402, Generator Loss: 4.790593147277832\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.15209245029836893, Generator Loss: 4.777726173400879\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.14400021452456713, Generator Loss: 4.861032009124756\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.13206822704523802, Generator Loss: 4.873405456542969\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.13052662461996078, Generator Loss: 4.898062705993652\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.13590864464640617, Generator Loss: 4.916839599609375\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.14517992362380028, Generator Loss: 4.980541229248047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.12338946061208844, Generator Loss: 4.913860321044922\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.1227895813062787, Generator Loss: 4.888773441314697\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.14954091608524323, Generator Loss: 4.951233386993408\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.1295550256036222, Generator Loss: 4.83941125869751\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.10916893370449543, Generator Loss: 4.857895374298096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.10453635174781084, Generator Loss: 4.937276840209961\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.1081499308347702, Generator Loss: 4.900196075439453\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.10203719954006374, Generator Loss: 4.902648448944092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.13012153981253505, Generator Loss: 4.939781188964844\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.10256442427635193, Generator Loss: 4.957664489746094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.09663014393299818, Generator Loss: 4.913491249084473\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.08852871926501393, Generator Loss: 4.8744330406188965\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.10717304656282067, Generator Loss: 4.876002311706543\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.1170918783172965, Generator Loss: 4.905449390411377\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.11492981621995568, Generator Loss: 4.972997665405273\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.09575289767235518, Generator Loss: 4.970607757568359\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.10510664153844118, Generator Loss: 5.056364059448242\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.10239101946353912, Generator Loss: 4.897860527038574\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.09921275405213237, Generator Loss: 4.876406669616699\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.09175195079296827, Generator Loss: 4.945963382720947\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.0970755279995501, Generator Loss: 4.916603088378906\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.07257392723113298, Generator Loss: 5.0158257484436035\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.081153379753232, Generator Loss: 5.023490905761719\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.08005358092486858, Generator Loss: 5.01579475402832\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.09150593867525458, Generator Loss: 5.130931854248047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.07593160029500723, Generator Loss: 5.063169479370117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.07119494117796421, Generator Loss: 5.03208065032959\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.08614023844711483, Generator Loss: 5.132538795471191\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.06960693607106805, Generator Loss: 5.093289375305176\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.06648959405720234, Generator Loss: 5.143780708312988\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.08124543214216828, Generator Loss: 5.073010444641113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.060351196909323335, Generator Loss: 5.084995269775391\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.056516668759286404, Generator Loss: 5.119918346405029\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.07486240286380053, Generator Loss: 5.131026268005371\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.06640202016569674, Generator Loss: 5.091549873352051\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.06531579047441483, Generator Loss: 5.125292778015137\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.051482305862009525, Generator Loss: 5.11444616317749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam"
      ],
      "metadata": {
        "id": "tp56V3Ly4oar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXo-wjW34pDJ",
        "outputId": "01f1a1d8-09fd-4e34-a700-b34d9e2c6eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 1.0912537276744843, Generator Loss: 0.8375904560089111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.9141736626625061, Generator Loss: 1.2766445875167847\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.8652187436819077, Generator Loss: 1.7646663188934326\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.8285566121339798, Generator Loss: 2.2488136291503906\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.8103710040450096, Generator Loss: 2.7206499576568604\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.7277082670480013, Generator Loss: 3.1161065101623535\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.7112441658973694, Generator Loss: 3.4289469718933105\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.6682219263166189, Generator Loss: 3.7168571949005127\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.6214813003316522, Generator Loss: 3.937293529510498\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.6618883088231087, Generator Loss: 4.121671199798584\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.6391747556626797, Generator Loss: 4.247623443603516\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.6449263459071517, Generator Loss: 4.328137397766113\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.6480080671608448, Generator Loss: 4.439020156860352\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.6619462110102177, Generator Loss: 4.478760719299316\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.7171130399219692, Generator Loss: 4.519630432128906\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.5739805130288005, Generator Loss: 4.519461154937744\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.6003590845502913, Generator Loss: 4.540775299072266\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.6099521303549409, Generator Loss: 4.523054122924805\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.6489486405625939, Generator Loss: 4.52004337310791\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.6094997161999345, Generator Loss: 4.470827579498291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.6278279265388846, Generator Loss: 4.481992721557617\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.6401909850537777, Generator Loss: 4.458021640777588\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.5519350478425622, Generator Loss: 4.439414024353027\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.49848959408700466, Generator Loss: 4.366533279418945\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.5322586428374052, Generator Loss: 4.354796409606934\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.6665545850992203, Generator Loss: 4.331879138946533\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.5990487225353718, Generator Loss: 4.317730903625488\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.4868968641385436, Generator Loss: 4.228954315185547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.5358155965805054, Generator Loss: 4.278850555419922\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.5691867456771433, Generator Loss: 4.192700386047363\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.484981675632298, Generator Loss: 4.167197227478027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.486194321885705, Generator Loss: 4.1591620445251465\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.5625093299895525, Generator Loss: 4.110576629638672\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.4674076456576586, Generator Loss: 4.1278839111328125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.5863762740045786, Generator Loss: 4.057337760925293\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.4997497433796525, Generator Loss: 4.031636714935303\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.4517679987475276, Generator Loss: 4.0345611572265625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.47665686532855034, Generator Loss: 4.031734943389893\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.41539112478494644, Generator Loss: 4.0104827880859375\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.4894851241260767, Generator Loss: 3.9487271308898926\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.4789513489231467, Generator Loss: 3.9761414527893066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.5115795936435461, Generator Loss: 3.957001209259033\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.4731050729751587, Generator Loss: 3.9449946880340576\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.4386637210845947, Generator Loss: 3.9151690006256104\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.464775862172246, Generator Loss: 3.972435474395752\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.3959301598370075, Generator Loss: 3.9399216175079346\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.4136552643030882, Generator Loss: 3.9816603660583496\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.4081190237775445, Generator Loss: 3.9758243560791016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.39573000837117434, Generator Loss: 3.992309093475342\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.3977230694144964, Generator Loss: 3.9947080612182617\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.4134729225188494, Generator Loss: 3.9998064041137695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.38115386851131916, Generator Loss: 4.005618572235107\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.35877033323049545, Generator Loss: 4.01467227935791\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.42801645398139954, Generator Loss: 4.053930282592773\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.38171409629285336, Generator Loss: 4.054635047912598\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.40085498057305813, Generator Loss: 4.010524749755859\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.3895709440112114, Generator Loss: 4.065858840942383\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.4128993842750788, Generator Loss: 4.057801246643066\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.36175770685076714, Generator Loss: 4.016549110412598\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.32950450852513313, Generator Loss: 4.02634334564209\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.3474651873111725, Generator Loss: 3.978062391281128\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.35652772802859545, Generator Loss: 3.9618959426879883\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.3507857136428356, Generator Loss: 4.010232448577881\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.3334721736609936, Generator Loss: 3.9808168411254883\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.2723360499367118, Generator Loss: 4.065587997436523\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.28309288062155247, Generator Loss: 3.988389015197754\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.2735686507076025, Generator Loss: 4.010869979858398\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.3717290870845318, Generator Loss: 4.10013484954834\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.26918979175388813, Generator Loss: 4.054010391235352\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.3420673403888941, Generator Loss: 4.04133939743042\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.2407987155020237, Generator Loss: 4.061530113220215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.2522602928802371, Generator Loss: 4.113751411437988\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.27452030312269926, Generator Loss: 4.069266319274902\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.3434228701516986, Generator Loss: 4.0752105712890625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.28707967698574066, Generator Loss: 4.134425163269043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.2730815801769495, Generator Loss: 4.0341081619262695\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.27115003392100334, Generator Loss: 4.069977283477783\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.28616926446557045, Generator Loss: 4.118532657623291\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.25246109440922737, Generator Loss: 4.1158528327941895\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.2725214483216405, Generator Loss: 4.158543109893799\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.2735862089321017, Generator Loss: 4.062522888183594\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.2778356382623315, Generator Loss: 4.105594635009766\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.30852531269192696, Generator Loss: 4.169750213623047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.2646678891032934, Generator Loss: 4.17702579498291\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.2543365862220526, Generator Loss: 4.234955787658691\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.29669325798749924, Generator Loss: 4.224527359008789\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.3057421068660915, Generator Loss: 4.214033126831055\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.30117890425026417, Generator Loss: 4.075908660888672\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.24148703925311565, Generator Loss: 4.231247901916504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.21552861668169498, Generator Loss: 4.209254264831543\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.2176708122715354, Generator Loss: 4.202034950256348\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.23022754956036806, Generator Loss: 4.175030708312988\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.23534748330712318, Generator Loss: 4.188714027404785\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.2539737541228533, Generator Loss: 4.142403602600098\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.23166581243276596, Generator Loss: 4.013204097747803\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.2777471328154206, Generator Loss: 4.201509475708008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.19961195066571236, Generator Loss: 4.209188461303711\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.20912028662860394, Generator Loss: 4.167951583862305\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.2074436079710722, Generator Loss: 4.122718334197998\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.1789083518087864, Generator Loss: 4.167590141296387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adamax"
      ],
      "metadata": {
        "id": "AUI8owey4oI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adamax(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adamax(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ixUTTy4q1Y",
        "outputId": "a31c6ec3-41cb-45b6-e484-5f6207ba2f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.7871482074260712, Generator Loss: 0.6588345766067505\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.6783224642276764, Generator Loss: 0.8688931465148926\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.662421315908432, Generator Loss: 1.0964429378509521\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.5785346031188965, Generator Loss: 1.3306801319122314\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.5217867791652679, Generator Loss: 1.5755902528762817\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.4863128513097763, Generator Loss: 1.7727508544921875\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.38719528913497925, Generator Loss: 1.9677329063415527\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.380653440952301, Generator Loss: 2.13445782661438\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.4176584891974926, Generator Loss: 2.2767953872680664\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.38238997012376785, Generator Loss: 2.383256435394287\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.36047733947634697, Generator Loss: 2.4845170974731445\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.44542909041047096, Generator Loss: 2.576639413833618\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.4295869320631027, Generator Loss: 2.646026134490967\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.3622538521885872, Generator Loss: 2.6930222511291504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.3638314828276634, Generator Loss: 2.748234748840332\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.38733766973018646, Generator Loss: 2.794894218444824\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.37933602556586266, Generator Loss: 2.837818145751953\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.3653242029249668, Generator Loss: 2.85445499420166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.3440532833337784, Generator Loss: 2.8633248805999756\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.3747981544584036, Generator Loss: 2.869037628173828\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.36244038864970207, Generator Loss: 2.9079277515411377\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.35578764602541924, Generator Loss: 2.8908939361572266\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.3390977121889591, Generator Loss: 2.9166316986083984\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.41163971461355686, Generator Loss: 2.9305343627929688\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.34964511170983315, Generator Loss: 2.9345145225524902\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.3335245680063963, Generator Loss: 2.922926425933838\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.402716938406229, Generator Loss: 2.973939895629883\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.36189463920891285, Generator Loss: 2.920949697494507\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.39278035052120686, Generator Loss: 2.912684440612793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.3461862578988075, Generator Loss: 2.910536766052246\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.3298983462154865, Generator Loss: 2.937224864959717\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.2887280024588108, Generator Loss: 2.9147911071777344\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.38072196394205093, Generator Loss: 2.913208484649658\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.32239098846912384, Generator Loss: 2.9381186962127686\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.33091056533157825, Generator Loss: 2.9172720909118652\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.3145619407296181, Generator Loss: 2.876237630844116\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.3270011432468891, Generator Loss: 2.8736767768859863\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.33807693235576153, Generator Loss: 2.8893394470214844\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.3489658758044243, Generator Loss: 2.8546652793884277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.3126939982175827, Generator Loss: 2.8806943893432617\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.35716069489717484, Generator Loss: 2.8535056114196777\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.33146238327026367, Generator Loss: 2.8660945892333984\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.3235800489783287, Generator Loss: 2.8502564430236816\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.29202985763549805, Generator Loss: 2.8227310180664062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.32736894860863686, Generator Loss: 2.822157382965088\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.3556700013577938, Generator Loss: 2.8579087257385254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.2910724803805351, Generator Loss: 2.8770952224731445\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.3212913293391466, Generator Loss: 2.887969493865967\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.26806338131427765, Generator Loss: 2.872732162475586\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.287030853331089, Generator Loss: 2.9191503524780273\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.2991739921271801, Generator Loss: 2.831284999847412\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.29823969304561615, Generator Loss: 2.861858367919922\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.29274948686361313, Generator Loss: 2.8964271545410156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.30764081329107285, Generator Loss: 2.8675899505615234\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.30646923929452896, Generator Loss: 2.8837366104125977\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.31950923800468445, Generator Loss: 2.887659788131714\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.29916830360889435, Generator Loss: 2.9062938690185547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.26981867477297783, Generator Loss: 2.88456392288208\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.25018854066729546, Generator Loss: 2.874340534210205\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.2831108048558235, Generator Loss: 2.9311306476593018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.30850328505039215, Generator Loss: 2.8682565689086914\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.2970368806272745, Generator Loss: 2.8959460258483887\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.33134149946272373, Generator Loss: 2.8871946334838867\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.2487342804670334, Generator Loss: 2.8869662284851074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.2787966653704643, Generator Loss: 2.8713274002075195\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.3083028942346573, Generator Loss: 2.9018118381500244\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.2755722962319851, Generator Loss: 2.905369520187378\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.2952449470758438, Generator Loss: 2.876382827758789\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.2805310748517513, Generator Loss: 2.9153106212615967\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.274244524538517, Generator Loss: 2.8973867893218994\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.2980240695178509, Generator Loss: 2.9033687114715576\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.27580852806568146, Generator Loss: 2.897768974304199\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.28933652862906456, Generator Loss: 2.8824448585510254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.26104139536619186, Generator Loss: 2.9849350452423096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.27743925899267197, Generator Loss: 2.9374003410339355\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.2776980437338352, Generator Loss: 2.928427219390869\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.26839226484298706, Generator Loss: 2.9634580612182617\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.2538347356021404, Generator Loss: 2.942514419555664\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.27614481188356876, Generator Loss: 2.96895694732666\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.2404603250324726, Generator Loss: 2.9979286193847656\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.21541184931993484, Generator Loss: 2.96578049659729\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.24229009076952934, Generator Loss: 2.944772243499756\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.24630477651953697, Generator Loss: 2.965075969696045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.2717224098742008, Generator Loss: 3.0133755207061768\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.25771308317780495, Generator Loss: 2.994476795196533\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.2490273155272007, Generator Loss: 2.937852621078491\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.28567301854491234, Generator Loss: 2.9667787551879883\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.22898955643177032, Generator Loss: 2.919025421142578\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.20595519989728928, Generator Loss: 2.9832043647766113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.28015509620308876, Generator Loss: 3.0294156074523926\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.25866258703172207, Generator Loss: 2.9545271396636963\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.2098301313817501, Generator Loss: 2.998994827270508\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.230271577835083, Generator Loss: 3.0087547302246094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.23223740607500076, Generator Loss: 3.0021843910217285\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.2062342818826437, Generator Loss: 3.0498476028442383\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.21491782367229462, Generator Loss: 3.0016613006591797\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.2390824407339096, Generator Loss: 3.00478458404541\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.24015672504901886, Generator Loss: 3.043476104736328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.25657612457871437, Generator Loss: 3.049063205718994\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.24711536802351475, Generator Loss: 2.9732508659362793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nadam"
      ],
      "metadata": {
        "id": "QhsnBbPk4r4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Nadam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Nadam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw2f-Zt84scW",
        "outputId": "8fbaa8d7-f850-4a24-d92b-b60a9f44e543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.517255574464798, Generator Loss: 1.6962848901748657\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.4842006489634514, Generator Loss: 1.9504759311676025\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.45045557618141174, Generator Loss: 2.171443462371826\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.4428761526942253, Generator Loss: 2.4050846099853516\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.48130281269550323, Generator Loss: 2.643372058868408\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.4526028484106064, Generator Loss: 2.853687286376953\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.35573171451687813, Generator Loss: 3.0525307655334473\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.37073860689997673, Generator Loss: 3.222857713699341\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.35393407568335533, Generator Loss: 3.3715310096740723\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.3583990763872862, Generator Loss: 3.516010284423828\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.3415415519848466, Generator Loss: 3.6356201171875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.33063375018537045, Generator Loss: 3.7376222610473633\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.40578718110919, Generator Loss: 3.8108630180358887\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.2848366815596819, Generator Loss: 3.8984413146972656\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.3340406557545066, Generator Loss: 3.96502947807312\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.31079413928091526, Generator Loss: 4.006951808929443\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.31114428862929344, Generator Loss: 4.058743000030518\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.3274097107350826, Generator Loss: 4.112536430358887\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.26172740664333105, Generator Loss: 4.153325080871582\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.3364091347903013, Generator Loss: 4.15784215927124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.33606037218123674, Generator Loss: 4.18331241607666\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.3517870670184493, Generator Loss: 4.226642608642578\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.2732227183878422, Generator Loss: 4.22383451461792\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.2977788816206157, Generator Loss: 4.221386432647705\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.28892272152006626, Generator Loss: 4.214049339294434\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.2755699371919036, Generator Loss: 4.2375335693359375\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.2503745388239622, Generator Loss: 4.2135419845581055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.24597690347582102, Generator Loss: 4.228109359741211\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.23146620905026793, Generator Loss: 4.240601539611816\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.24720161966979504, Generator Loss: 4.218108177185059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.2666460610926151, Generator Loss: 4.21113920211792\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.3049106653779745, Generator Loss: 4.193972587585449\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.2631175871938467, Generator Loss: 4.233599662780762\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.2430573869496584, Generator Loss: 4.183110237121582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.23005892988294363, Generator Loss: 4.2098894119262695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.21518951561301947, Generator Loss: 4.202510833740234\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.2562443846836686, Generator Loss: 4.201784610748291\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.2107391506433487, Generator Loss: 4.195911407470703\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.22532008681446314, Generator Loss: 4.2085700035095215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.21181609388440847, Generator Loss: 4.156593322753906\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.2287931703031063, Generator Loss: 4.174238681793213\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.2327201310545206, Generator Loss: 4.13667631149292\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.2775777969509363, Generator Loss: 4.137900352478027\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.20529511757194996, Generator Loss: 4.1164231300354\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.23095847852528095, Generator Loss: 4.173375129699707\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.2005956768989563, Generator Loss: 4.179764747619629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.20077669247984886, Generator Loss: 4.1157965660095215\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.1905592978000641, Generator Loss: 4.139256000518799\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.23555961437523365, Generator Loss: 4.158628940582275\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.19154498353600502, Generator Loss: 4.1313090324401855\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.1827208325266838, Generator Loss: 4.087829113006592\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.18363195285201073, Generator Loss: 4.0962629318237305\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.2071799337863922, Generator Loss: 4.186849594116211\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.20435659028589725, Generator Loss: 4.18599796295166\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.22123009990900755, Generator Loss: 4.1126275062561035\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.1449831873178482, Generator Loss: 4.147904396057129\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.20172628201544285, Generator Loss: 4.095606327056885\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.1624380201101303, Generator Loss: 4.0592041015625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.19518504291772842, Generator Loss: 4.114823341369629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.1704080319032073, Generator Loss: 4.179019451141357\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.17836824618279934, Generator Loss: 4.079052448272705\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.1467692293226719, Generator Loss: 4.014840126037598\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.15976697206497192, Generator Loss: 4.123804569244385\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.2052457584068179, Generator Loss: 4.11358642578125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.14506937935948372, Generator Loss: 4.168858528137207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.17835351638495922, Generator Loss: 4.117344856262207\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.15911798644810915, Generator Loss: 4.10095739364624\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.15666228532791138, Generator Loss: 4.1676435470581055\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.1264318712055683, Generator Loss: 4.0393290519714355\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.1298191100358963, Generator Loss: 4.054201126098633\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.12143783271312714, Generator Loss: 4.120170593261719\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.17049832735210657, Generator Loss: 4.181631565093994\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.1343122599646449, Generator Loss: 4.190493583679199\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.15515486523509026, Generator Loss: 4.096297740936279\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.10767327807843685, Generator Loss: 4.273100852966309\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.14265644177794456, Generator Loss: 4.223254203796387\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.13664857111871243, Generator Loss: 4.2197585105896\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.15784250851720572, Generator Loss: 4.296482563018799\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.12359013222157955, Generator Loss: 4.261965751647949\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.13119205133989453, Generator Loss: 4.290065288543701\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.12430009618401527, Generator Loss: 4.270174980163574\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.11258316040039062, Generator Loss: 4.287018775939941\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.1440301612019539, Generator Loss: 4.283639907836914\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.13522167969495058, Generator Loss: 4.188859939575195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.12078248523175716, Generator Loss: 4.211549758911133\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.09974751994013786, Generator Loss: 4.2729644775390625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.13332968205213547, Generator Loss: 4.297924995422363\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.09960993565618992, Generator Loss: 4.252485275268555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.12274685315787792, Generator Loss: 4.234235763549805\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.10650838073343039, Generator Loss: 4.220934867858887\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.12107452657073736, Generator Loss: 4.268625736236572\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.10584485996514559, Generator Loss: 4.318009853363037\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.12136314436793327, Generator Loss: 4.357332229614258\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.09945542924106121, Generator Loss: 4.3339996337890625\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.0869059320539236, Generator Loss: 4.237642288208008\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.11745383776724339, Generator Loss: 4.464282989501953\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.0868016816675663, Generator Loss: 4.334288120269775\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.09642237890511751, Generator Loss: 4.280098915100098\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.09443291276693344, Generator Loss: 4.426586151123047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.10402934812009335, Generator Loss: 4.321353435516357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adagrad"
      ],
      "metadata": {
        "id": "m9iJXqSy4uId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import Adagrad\n",
        "\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adagrad(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adagrad(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw6ROT7Q4ug-",
        "outputId": "4ee08e58-a716-4547-efc0-b08bd9bf7f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1/100, Discriminator Loss: 1.1328797340393066, Generator Loss: 1.3906285762786865\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 1.1036754250526428, Generator Loss: 1.4057244062423706\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 1.0293585807085037, Generator Loss: 1.435567855834961\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4/100, Discriminator Loss: 1.150167465209961, Generator Loss: 1.4592020511627197\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 1.087673395872116, Generator Loss: 1.4797892570495605\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.9341898411512375, Generator Loss: 1.501943588256836\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 7/100, Discriminator Loss: 1.0738927870988846, Generator Loss: 1.5249216556549072\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 8/100, Discriminator Loss: 1.0771999657154083, Generator Loss: 1.5244262218475342\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9/100, Discriminator Loss: 1.0824183821678162, Generator Loss: 1.5532482862472534\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10/100, Discriminator Loss: 1.0030374228954315, Generator Loss: 1.5630593299865723\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 1.018976092338562, Generator Loss: 1.5969908237457275\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 1.0232910886406898, Generator Loss: 1.5969760417938232\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.9796465486288071, Generator Loss: 1.6223413944244385\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.9860146790742874, Generator Loss: 1.6344274282455444\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.9999467432498932, Generator Loss: 1.6517876386642456\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.9529717415571213, Generator Loss: 1.6716258525848389\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.9920736774802208, Generator Loss: 1.677636742591858\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.9390372484922409, Generator Loss: 1.7185710668563843\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.9907072633504868, Generator Loss: 1.7103855609893799\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.9953217953443527, Generator Loss: 1.7340326309204102\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.9090152010321617, Generator Loss: 1.747145652770996\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.9198318496346474, Generator Loss: 1.758496642112732\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.9987189620733261, Generator Loss: 1.785871148109436\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.9417010396718979, Generator Loss: 1.7960362434387207\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.9473629966378212, Generator Loss: 1.8225858211517334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.8812464401125908, Generator Loss: 1.8114432096481323\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.8928242027759552, Generator Loss: 1.8234148025512695\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.8766501098871231, Generator Loss: 1.854691743850708\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.9927509129047394, Generator Loss: 1.8671165704727173\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.9597733467817307, Generator Loss: 1.8785014152526855\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.9310536310076714, Generator Loss: 1.8913097381591797\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.9303597062826157, Generator Loss: 1.90833580493927\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 1.1011016815900803, Generator Loss: 1.9065451622009277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.885018065571785, Generator Loss: 1.921961784362793\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.9303680211305618, Generator Loss: 1.9407129287719727\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.9091902300715446, Generator Loss: 1.9433640241622925\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.9626146480441093, Generator Loss: 1.9546799659729004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.9223387911915779, Generator Loss: 1.9800465106964111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 1.0772117748856544, Generator Loss: 1.9754629135131836\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.900043174624443, Generator Loss: 2.0096514225006104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.9497916400432587, Generator Loss: 2.023237943649292\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.8804583698511124, Generator Loss: 2.0128884315490723\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 1.0455857068300247, Generator Loss: 2.04660964012146\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44/100, Discriminator Loss: 1.0004160702228546, Generator Loss: 2.0538406372070312\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.9220113083720207, Generator Loss: 2.0528650283813477\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.9958367496728897, Generator Loss: 2.075815200805664\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 1.0105222463607788, Generator Loss: 2.0719668865203857\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.8030606284737587, Generator Loss: 2.090205669403076\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.8974386975169182, Generator Loss: 2.106734037399292\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.8493363335728645, Generator Loss: 2.117600440979004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.9032828509807587, Generator Loss: 2.123324394226074\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.8999362587928772, Generator Loss: 2.1330678462982178\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.8309901654720306, Generator Loss: 2.13456392288208\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.9192470274865627, Generator Loss: 2.148000955581665\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.997992742806673, Generator Loss: 2.1677045822143555\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.8498249500989914, Generator Loss: 2.15128231048584\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.8963105753064156, Generator Loss: 2.1807687282562256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.8978335410356522, Generator Loss: 2.1884775161743164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.8988985866308212, Generator Loss: 2.197237253189087\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.9306988418102264, Generator Loss: 2.203340768814087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.9224909916520119, Generator Loss: 2.214505672454834\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.8960839211940765, Generator Loss: 2.211801052093506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.8701954707503319, Generator Loss: 2.2509570121765137\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.8534568659961224, Generator Loss: 2.2457852363586426\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.911580964922905, Generator Loss: 2.249661922454834\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.961185235530138, Generator Loss: 2.252533435821533\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.8845999278128147, Generator Loss: 2.272670030593872\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.894620131701231, Generator Loss: 2.2788209915161133\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.9433760307729244, Generator Loss: 2.288038969039917\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.8847627900540829, Generator Loss: 2.295742988586426\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.8442726135253906, Generator Loss: 2.2973082065582275\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.9457745105028152, Generator Loss: 2.297173023223877\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.9651291817426682, Generator Loss: 2.3142404556274414\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.9124999418854713, Generator Loss: 2.313375473022461\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.9201519824564457, Generator Loss: 2.3364386558532715\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.9488535411655903, Generator Loss: 2.350660800933838\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.8854432553052902, Generator Loss: 2.3569090366363525\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.9691525660455227, Generator Loss: 2.358412504196167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.8962337151169777, Generator Loss: 2.3734564781188965\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.8389093577861786, Generator Loss: 2.3800861835479736\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.8818287439644337, Generator Loss: 2.3773975372314453\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.8392431363463402, Generator Loss: 2.381523609161377\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.8654309585690498, Generator Loss: 2.3847713470458984\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.7655088678002357, Generator Loss: 2.397728204727173\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.8077958039939404, Generator Loss: 2.4139461517333984\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.9130866676568985, Generator Loss: 2.4070682525634766\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.9161551855504513, Generator Loss: 2.4032468795776367\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.8427961245179176, Generator Loss: 2.4265472888946533\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.9509856030344963, Generator Loss: 2.434241771697998\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.7890845760703087, Generator Loss: 2.440901517868042\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.8967226967215538, Generator Loss: 2.451749801635742\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.9083937928080559, Generator Loss: 2.456760883331299\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.8500354886054993, Generator Loss: 2.4553799629211426\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.8685234114527702, Generator Loss: 2.458545684814453\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.9628173932433128, Generator Loss: 2.456294059753418\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.9028244689106941, Generator Loss: 2.474059581756592\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.8496941700577736, Generator Loss: 2.48459792137146\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.8882760293781757, Generator Loss: 2.488755226135254\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.900627426803112, Generator Loss: 2.495901346206665\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.9201457127928734, Generator Loss: 2.5128366947174072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaDelta"
      ],
      "metadata": {
        "id": "0RdM1oAW4uy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import Adadelta\n",
        "\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adadelta(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adadelta(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t3a6o3T4wGp",
        "outputId": "d3414cdf-4e01-49d3-e18e-d99f51b0fb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.7126422822475433, Generator Loss: 1.1439472436904907\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.7737583816051483, Generator Loss: 1.1377840042114258\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.7376970499753952, Generator Loss: 1.141035556793213\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.7167271971702576, Generator Loss: 1.142885684967041\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.7954206764698029, Generator Loss: 1.1386210918426514\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.7253158837556839, Generator Loss: 1.1329257488250732\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.755130872130394, Generator Loss: 1.1369915008544922\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.7231592535972595, Generator Loss: 1.1421310901641846\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.6768568158149719, Generator Loss: 1.139670968055725\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.7111382782459259, Generator Loss: 1.1505861282348633\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.7626679837703705, Generator Loss: 1.145479440689087\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.7171673625707626, Generator Loss: 1.1488020420074463\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.7983904480934143, Generator Loss: 1.1491999626159668\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.6727218925952911, Generator Loss: 1.1475276947021484\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.6600369811058044, Generator Loss: 1.1422793865203857\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.7478402107954025, Generator Loss: 1.147236943244934\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.6308622360229492, Generator Loss: 1.1540309190750122\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.6472323536872864, Generator Loss: 1.1533362865447998\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.7652541846036911, Generator Loss: 1.1532400846481323\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.6698467433452606, Generator Loss: 1.1482043266296387\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.7365200519561768, Generator Loss: 1.1480768918991089\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.6895733773708344, Generator Loss: 1.1515686511993408\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.769731804728508, Generator Loss: 1.1492846012115479\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.6667676120996475, Generator Loss: 1.154184103012085\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.7342620193958282, Generator Loss: 1.1519019603729248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.6510775983333588, Generator Loss: 1.1511473655700684\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.701513797044754, Generator Loss: 1.1576616764068604\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.7635801881551743, Generator Loss: 1.1571550369262695\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.743655800819397, Generator Loss: 1.147597074508667\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.7433467209339142, Generator Loss: 1.1581575870513916\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.7201895415782928, Generator Loss: 1.1558899879455566\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.7715163081884384, Generator Loss: 1.16373610496521\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.6716859638690948, Generator Loss: 1.1646502017974854\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.7606285959482193, Generator Loss: 1.162062644958496\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.7279418259859085, Generator Loss: 1.1530396938323975\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.6724192053079605, Generator Loss: 1.1565520763397217\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.7115787863731384, Generator Loss: 1.1572902202606201\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.7522958815097809, Generator Loss: 1.1575019359588623\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.6586921215057373, Generator Loss: 1.1648352146148682\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.7385165840387344, Generator Loss: 1.158205270767212\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.7164502441883087, Generator Loss: 1.1662251949310303\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.7473587542772293, Generator Loss: 1.1570342779159546\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.6862461715936661, Generator Loss: 1.172253131866455\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.7914248108863831, Generator Loss: 1.1696038246154785\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.7649736106395721, Generator Loss: 1.1651387214660645\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.6894337832927704, Generator Loss: 1.1548526287078857\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.7089184522628784, Generator Loss: 1.1628764867782593\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.7217735350131989, Generator Loss: 1.1756460666656494\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.7489200830459595, Generator Loss: 1.1724283695220947\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.7069699764251709, Generator Loss: 1.1687862873077393\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.8493922501802444, Generator Loss: 1.172114372253418\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.6662927865982056, Generator Loss: 1.1692003011703491\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.6642818301916122, Generator Loss: 1.163608193397522\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.6519930511713028, Generator Loss: 1.164463758468628\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.7302605509757996, Generator Loss: 1.161802887916565\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.8185872137546539, Generator Loss: 1.1703402996063232\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.7054653614759445, Generator Loss: 1.168447732925415\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.6962066292762756, Generator Loss: 1.1718862056732178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.6895609200000763, Generator Loss: 1.1692352294921875\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.6635251939296722, Generator Loss: 1.1838390827178955\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.6898203790187836, Generator Loss: 1.1756019592285156\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.6450585722923279, Generator Loss: 1.1742838621139526\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.6999050676822662, Generator Loss: 1.1817528009414673\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.7563220709562302, Generator Loss: 1.1739540100097656\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.8629969358444214, Generator Loss: 1.1873220205307007\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.6695925295352936, Generator Loss: 1.169574499130249\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.6896611005067825, Generator Loss: 1.183035135269165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.7591658532619476, Generator Loss: 1.1754939556121826\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.7238440215587616, Generator Loss: 1.174530267715454\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.7737640142440796, Generator Loss: 1.1814119815826416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.7529879957437515, Generator Loss: 1.1824482679367065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.6885140538215637, Generator Loss: 1.1792821884155273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.7565833032131195, Generator Loss: 1.1817042827606201\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.7716014981269836, Generator Loss: 1.1802371740341187\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.6948060393333435, Generator Loss: 1.1800535917282104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.6704305410385132, Generator Loss: 1.1896322965621948\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.7204776108264923, Generator Loss: 1.1800007820129395\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.6927971243858337, Generator Loss: 1.17782723903656\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.7469651848077774, Generator Loss: 1.1938718557357788\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.6731458157300949, Generator Loss: 1.1809585094451904\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.7008965760469437, Generator Loss: 1.1870090961456299\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.7317948192358017, Generator Loss: 1.1858007907867432\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.7629124224185944, Generator Loss: 1.194610357284546\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.7311290800571442, Generator Loss: 1.1900990009307861\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.6855377554893494, Generator Loss: 1.1922035217285156\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.8010706901550293, Generator Loss: 1.194696307182312\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.7025580555200577, Generator Loss: 1.1804120540618896\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.6890508383512497, Generator Loss: 1.193507432937622\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.7866816520690918, Generator Loss: 1.191571831703186\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.7020393013954163, Generator Loss: 1.1851770877838135\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.6866709291934967, Generator Loss: 1.1967883110046387\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.6710854172706604, Generator Loss: 1.1893792152404785\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.6895545423030853, Generator Loss: 1.197427749633789\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.7496760785579681, Generator Loss: 1.1962915658950806\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.7266358882188797, Generator Loss: 1.1947786808013916\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.7269068360328674, Generator Loss: 1.191969394683838\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.791871502995491, Generator Loss: 1.1883118152618408\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.7140646278858185, Generator Loss: 1.1955935955047607\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.7508782595396042, Generator Loss: 1.1965787410736084\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.7021536231040955, Generator Loss: 1.192707896232605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best optimizer = adam (commonly used in GAN).\n",
        "Epoch 100/100, Discriminator Loss: 0.1789083518087864, Generator Loss: 4.167590141296387"
      ],
      "metadata": {
        "id": "llCNavEX4xNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimenting Best Output Activation Function\n"
      ],
      "metadata": {
        "id": "uPdlGfGF4yqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output relu"
      ],
      "metadata": {
        "id": "Iu5HKSiy41sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='relu'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='relu')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb08PsAe4z5o",
        "outputId": "9c6c95f4-34b7-4390-ff63-45e6d1ad4bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1/100, Discriminator Loss: 6.0574450343847275, Generator Loss: 7.489331245422363\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 2/100, Discriminator Loss: 4.91982177644968, Generator Loss: 7.552118301391602\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 4.955460950732231, Generator Loss: 5.818508625030518\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 4/100, Discriminator Loss: 5.2745649963617325, Generator Loss: 5.218440055847168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 5/100, Discriminator Loss: 4.901006415486336, Generator Loss: 4.9548115730285645\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 4.441048711538315, Generator Loss: 4.2838826179504395\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 4.25408798456192, Generator Loss: 4.043478965759277\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 4.944410935044289, Generator Loss: 3.5758771896362305\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 9/100, Discriminator Loss: 4.7964010536670685, Generator Loss: 3.8171029090881348\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 10/100, Discriminator Loss: 3.777699261903763, Generator Loss: 2.8622140884399414\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 3.8182645440101624, Generator Loss: 2.4293739795684814\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 12/100, Discriminator Loss: 4.396359235048294, Generator Loss: 2.5960357189178467\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 4.001475960016251, Generator Loss: 1.9597114324569702\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14/100, Discriminator Loss: 3.9941307604312897, Generator Loss: 1.8406105041503906\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15/100, Discriminator Loss: 3.804820403456688, Generator Loss: 2.298609972000122\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 4.572841182351112, Generator Loss: 1.4268598556518555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 4.609013617038727, Generator Loss: 1.7445275783538818\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18/100, Discriminator Loss: 3.9358761310577393, Generator Loss: 2.1838042736053467\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 4.4783786833286285, Generator Loss: 2.0883545875549316\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 3.6364890038967133, Generator Loss: 1.96541428565979\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 4.032690033316612, Generator Loss: 2.157562255859375\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 4.046175107359886, Generator Loss: 1.9093587398529053\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 4.39097286760807, Generator Loss: 2.1874608993530273\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24/100, Discriminator Loss: 4.116582632064819, Generator Loss: 2.5758867263793945\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 3.9310877919197083, Generator Loss: 1.8993947505950928\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 3.7952072620391846, Generator Loss: 2.2989273071289062\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 3.9258934259414673, Generator Loss: 2.4452476501464844\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 4.469125032424927, Generator Loss: 1.7630045413970947\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 29/100, Discriminator Loss: 3.3598641753196716, Generator Loss: 1.5157196521759033\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 4.021583199501038, Generator Loss: 1.1365834474563599\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 3.419350743293762, Generator Loss: 1.3619694709777832\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32/100, Discriminator Loss: 3.5826520025730133, Generator Loss: 1.1971644163131714\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 3.5466166138648987, Generator Loss: 1.1807321310043335\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 3.7771454751491547, Generator Loss: 1.3784123659133911\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35/100, Discriminator Loss: 3.8211430609226227, Generator Loss: 1.3968068361282349\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 2.907932609319687, Generator Loss: 1.157510757446289\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 4.170893609523773, Generator Loss: 1.2678313255310059\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 3.4569756388664246, Generator Loss: 1.5403276681900024\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 39/100, Discriminator Loss: 3.21029794216156, Generator Loss: 1.3122742176055908\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40/100, Discriminator Loss: 3.1434167623519897, Generator Loss: 1.4146387577056885\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 41/100, Discriminator Loss: 3.9318940341472626, Generator Loss: 1.5282458066940308\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 42/100, Discriminator Loss: 2.853596493601799, Generator Loss: 1.5637634992599487\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 43/100, Discriminator Loss: 3.2095579504966736, Generator Loss: 2.1294033527374268\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 44/100, Discriminator Loss: 2.944204717874527, Generator Loss: 2.070582389831543\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 3.367670953273773, Generator Loss: 1.563336730003357\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 3.087102770805359, Generator Loss: 2.389111280441284\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 47/100, Discriminator Loss: 2.5866876244544983, Generator Loss: 1.72319757938385\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 3.0773582607507706, Generator Loss: 2.6908578872680664\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 3.5368486791849136, Generator Loss: 2.3228368759155273\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 3.2677083611488342, Generator Loss: 1.8775560855865479\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 51/100, Discriminator Loss: 2.095722645521164, Generator Loss: 2.101712703704834\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 52/100, Discriminator Loss: 3.0658904910087585, Generator Loss: 2.1247096061706543\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 3.0881169736385345, Generator Loss: 1.6745339632034302\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 2.9186111241579056, Generator Loss: 3.0211808681488037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 2.7800466120243073, Generator Loss: 2.603769063949585\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 3.3649565279483795, Generator Loss: 1.7300269603729248\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 57/100, Discriminator Loss: 3.232946813106537, Generator Loss: 2.096886396408081\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 3.2842013090848923, Generator Loss: 2.274947166442871\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 59/100, Discriminator Loss: 2.643578991293907, Generator Loss: 2.448638677597046\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 2.5306731462478638, Generator Loss: 2.305525779724121\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 61/100, Discriminator Loss: 2.4027477502822876, Generator Loss: 2.107562303543091\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 62/100, Discriminator Loss: 2.449066013097763, Generator Loss: 2.661593437194824\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 63/100, Discriminator Loss: 2.381463199853897, Generator Loss: 2.2323474884033203\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 64/100, Discriminator Loss: 2.616444170475006, Generator Loss: 2.4798474311828613\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 3.406705155968666, Generator Loss: 2.295295000076294\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 2.9014288783073425, Generator Loss: 2.030485153198242\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 67/100, Discriminator Loss: 2.936680719256401, Generator Loss: 3.0089545249938965\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 68/100, Discriminator Loss: 2.6304176598787308, Generator Loss: 2.425265312194824\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 69/100, Discriminator Loss: 2.9041506350040436, Generator Loss: 2.4152121543884277\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 70/100, Discriminator Loss: 2.009511277079582, Generator Loss: 3.140655040740967\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 71/100, Discriminator Loss: 2.997214213013649, Generator Loss: 3.1046035289764404\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 3.198840618133545, Generator Loss: 3.1063573360443115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 2.9699540436267853, Generator Loss: 4.043107986450195\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 2.1895410865545273, Generator Loss: 4.2360687255859375\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 75/100, Discriminator Loss: 2.252710074186325, Generator Loss: 4.352120399475098\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 76/100, Discriminator Loss: 1.7620015740394592, Generator Loss: 3.633767604827881\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 2.192531406879425, Generator Loss: 3.7087278366088867\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 2.3611203134059906, Generator Loss: 4.79313850402832\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 1.835493952035904, Generator Loss: 4.514801025390625\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 80/100, Discriminator Loss: 2.7148199006915092, Generator Loss: 4.761235237121582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 1.9674185812473297, Generator Loss: 4.965072154998779\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 2.264196664094925, Generator Loss: 5.409520626068115\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 2.7637834399938583, Generator Loss: 4.919538974761963\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 84/100, Discriminator Loss: 1.7393243312835693, Generator Loss: 4.944400310516357\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 1.976833164691925, Generator Loss: 4.484816551208496\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 86/100, Discriminator Loss: 2.06898795068264, Generator Loss: 3.9313206672668457\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 87/100, Discriminator Loss: 1.8011936843395233, Generator Loss: 3.9469048976898193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 1.842365063726902, Generator Loss: 5.570281982421875\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 89/100, Discriminator Loss: 2.3147167712450027, Generator Loss: 4.51785945892334\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 90/100, Discriminator Loss: 2.1627149134874344, Generator Loss: 4.470539093017578\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 1.8401373401284218, Generator Loss: 5.77614688873291\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 92/100, Discriminator Loss: 2.2523796632885933, Generator Loss: 5.96263313293457\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 93/100, Discriminator Loss: 1.687834471464157, Generator Loss: 4.905414581298828\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 94/100, Discriminator Loss: 2.1464991718530655, Generator Loss: 4.0073723793029785\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 1.3226185739040375, Generator Loss: 3.790626287460327\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 2.440152406692505, Generator Loss: 4.080986022949219\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 1.8201763406395912, Generator Loss: 4.767487049102783\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 1.6405305713415146, Generator Loss: 4.921070575714111\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 2.2163019478321075, Generator Loss: 4.841242790222168\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 100/100, Discriminator Loss: 1.4610454589128494, Generator Loss: 4.282404899597168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output LeakyReLU"
      ],
      "metadata": {
        "id": "ZC7llPQl42hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='LeakyReLU'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='LeakyReLU')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW5ppb4c45DC",
        "outputId": "3914787b-33c2-4973-9046-8bd29d6c65a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 4.497592464089394, Generator Loss: 5.717559814453125\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 5.219203278422356, Generator Loss: 5.034558296203613\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 4.56376188993454, Generator Loss: 3.2234902381896973\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4/100, Discriminator Loss: 5.703654408454895, Generator Loss: 1.9002270698547363\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 4.570112228393555, Generator Loss: 0.9297850131988525\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 4.655741989612579, Generator Loss: 1.0033323764801025\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 7/100, Discriminator Loss: 5.305236458778381, Generator Loss: 0.668152928352356\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 8/100, Discriminator Loss: 5.47045624256134, Generator Loss: 0.7346746921539307\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 9/100, Discriminator Loss: 5.1205655336380005, Generator Loss: 0.6609455347061157\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 10/100, Discriminator Loss: 5.232297301292419, Generator Loss: 0.6862093806266785\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 11/100, Discriminator Loss: 5.256671488285065, Generator Loss: 0.5313608646392822\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 12/100, Discriminator Loss: 6.053798079490662, Generator Loss: 0.5734922885894775\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 5.553079605102539, Generator Loss: 0.6443644165992737\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 6.265858769416809, Generator Loss: 0.6805624961853027\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15/100, Discriminator Loss: 5.2238858342170715, Generator Loss: 0.6355859637260437\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 5.03045380115509, Generator Loss: 0.822871208190918\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 4.834894180297852, Generator Loss: 0.6750627160072327\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18/100, Discriminator Loss: 4.928087949752808, Generator Loss: 0.596153736114502\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 4.322253406047821, Generator Loss: 0.7308317422866821\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 20/100, Discriminator Loss: 4.368840277194977, Generator Loss: 0.8007927536964417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 4.6338582038879395, Generator Loss: 0.6533467769622803\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 4.798402547836304, Generator Loss: 0.645203173160553\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 4.510544300079346, Generator Loss: 0.7170820236206055\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24/100, Discriminator Loss: 4.6545005440711975, Generator Loss: 0.8393939733505249\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 25/100, Discriminator Loss: 4.944783598184586, Generator Loss: 1.0727617740631104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 26/100, Discriminator Loss: 5.140493214130402, Generator Loss: 0.8743689060211182\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 3.884860336780548, Generator Loss: 0.7977955341339111\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28/100, Discriminator Loss: 4.612732172012329, Generator Loss: 0.7827643156051636\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 3.865914463996887, Generator Loss: 1.0606749057769775\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 4.956485986709595, Generator Loss: 0.7605565190315247\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 31/100, Discriminator Loss: 5.091634273529053, Generator Loss: 0.7893621325492859\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32/100, Discriminator Loss: 5.892066597938538, Generator Loss: 0.6770910024642944\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 33/100, Discriminator Loss: 4.85279107093811, Generator Loss: 0.7073408365249634\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 5.077321946620941, Generator Loss: 0.7451457977294922\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35/100, Discriminator Loss: 4.363044619560242, Generator Loss: 0.7109537124633789\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 4.062421202659607, Generator Loss: 0.6083384156227112\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 37/100, Discriminator Loss: 5.176826000213623, Generator Loss: 0.812877893447876\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 38/100, Discriminator Loss: 4.898071765899658, Generator Loss: 0.7548587918281555\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 4.423711776733398, Generator Loss: 0.7739067673683167\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 40/100, Discriminator Loss: 4.880545139312744, Generator Loss: 1.1615965366363525\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 41/100, Discriminator Loss: 4.249884933233261, Generator Loss: 0.9737581014633179\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 42/100, Discriminator Loss: 4.701133519411087, Generator Loss: 1.1736866235733032\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 43/100, Discriminator Loss: 4.617376297712326, Generator Loss: 1.2946856021881104\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 44/100, Discriminator Loss: 4.13529098033905, Generator Loss: 1.1226242780685425\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 4.250087857246399, Generator Loss: 1.173262357711792\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 46/100, Discriminator Loss: 4.115305066108704, Generator Loss: 1.371341586112976\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47/100, Discriminator Loss: 4.344364136457443, Generator Loss: 1.322826862335205\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 3.9468249082565308, Generator Loss: 0.8566072583198547\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 3.9682497382164, Generator Loss: 0.897881031036377\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 50/100, Discriminator Loss: 3.9842230677604675, Generator Loss: 0.7222859859466553\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51/100, Discriminator Loss: 4.957489728927612, Generator Loss: 0.8020224571228027\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 4.801600217819214, Generator Loss: 0.6803158521652222\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 4.478831470012665, Generator Loss: 0.8351527452468872\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 54/100, Discriminator Loss: 5.0110204219818115, Generator Loss: 1.1771306991577148\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 4.330127000808716, Generator Loss: 0.7994202971458435\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 56/100, Discriminator Loss: 4.057183027267456, Generator Loss: 0.7400838136672974\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 57/100, Discriminator Loss: 4.686530888080597, Generator Loss: 0.6786102056503296\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 4.368821084499359, Generator Loss: 0.7400509119033813\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 59/100, Discriminator Loss: 4.14997786283493, Generator Loss: 0.9807088375091553\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 60/100, Discriminator Loss: 4.153102099895477, Generator Loss: 0.8486064672470093\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 61/100, Discriminator Loss: 4.5208359360694885, Generator Loss: 0.9148560762405396\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 4.227947771549225, Generator Loss: 1.0397089719772339\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 63/100, Discriminator Loss: 3.9697617888450623, Generator Loss: 0.8897776007652283\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 64/100, Discriminator Loss: 4.629424631595612, Generator Loss: 1.1441706418991089\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 65/100, Discriminator Loss: 4.230090916156769, Generator Loss: 0.9203288555145264\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 66/100, Discriminator Loss: 4.338161885738373, Generator Loss: 1.1690213680267334\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 67/100, Discriminator Loss: 4.095901846885681, Generator Loss: 0.7767740488052368\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 68/100, Discriminator Loss: 4.215139031410217, Generator Loss: 0.7680516242980957\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 69/100, Discriminator Loss: 3.708681106567383, Generator Loss: 0.9191321730613708\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 3.891332745552063, Generator Loss: 0.7476516962051392\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 71/100, Discriminator Loss: 4.362434446811676, Generator Loss: 1.19297194480896\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 3.763071894645691, Generator Loss: 0.8649286031723022\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 73/100, Discriminator Loss: 3.8569151759147644, Generator Loss: 0.7695029377937317\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 74/100, Discriminator Loss: 3.773114800453186, Generator Loss: 1.0418734550476074\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 75/100, Discriminator Loss: 4.120851278305054, Generator Loss: 1.0308926105499268\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 76/100, Discriminator Loss: 3.3542353212833405, Generator Loss: 1.0843539237976074\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 77/100, Discriminator Loss: 4.597976207733154, Generator Loss: 1.2629005908966064\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 3.4164704382419586, Generator Loss: 1.5486021041870117\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 3.7546359300613403, Generator Loss: 1.3063160181045532\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 80/100, Discriminator Loss: 3.489688456058502, Generator Loss: 1.056657075881958\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 81/100, Discriminator Loss: 3.764359951019287, Generator Loss: 1.0633723735809326\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 82/100, Discriminator Loss: 3.526090085506439, Generator Loss: 0.9785677194595337\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 3.6304271817207336, Generator Loss: 1.1513817310333252\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 4.028053671121597, Generator Loss: 0.9742376804351807\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 85/100, Discriminator Loss: 3.741744637489319, Generator Loss: 1.4020867347717285\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 86/100, Discriminator Loss: 3.160118877887726, Generator Loss: 1.3397579193115234\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 3.4300886392593384, Generator Loss: 1.3070178031921387\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 88/100, Discriminator Loss: 3.7348830699920654, Generator Loss: 1.121539831161499\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 89/100, Discriminator Loss: 3.442394733428955, Generator Loss: 1.213682770729065\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 90/100, Discriminator Loss: 2.9922828376293182, Generator Loss: 1.3714938163757324\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 4.65035542845726, Generator Loss: 1.0595076084136963\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 92/100, Discriminator Loss: 3.3898505568504333, Generator Loss: 1.6926686763763428\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 93/100, Discriminator Loss: 3.7598596811294556, Generator Loss: 1.699629783630371\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 94/100, Discriminator Loss: 3.9493239521980286, Generator Loss: 1.5763276815414429\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 95/100, Discriminator Loss: 3.543352782726288, Generator Loss: 1.4940252304077148\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch 96/100, Discriminator Loss: 3.5208131968975067, Generator Loss: 2.1761066913604736\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 97/100, Discriminator Loss: 3.270070731639862, Generator Loss: 1.6258618831634521\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 98/100, Discriminator Loss: 3.665201872587204, Generator Loss: 1.1737639904022217\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 3.728788197040558, Generator Loss: 1.3527333736419678\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 100/100, Discriminator Loss: 3.4705618619918823, Generator Loss: 1.1494419574737549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output elu"
      ],
      "metadata": {
        "id": "AXXknjt845Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='elu'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='elu')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2oEkozH456A",
        "outputId": "ff1e6f05-fc34-43c9-dd23-9b94409b60e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 1/100, Discriminator Loss: 6.291070997714996, Generator Loss: 9.230876922607422\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 6.703990668058395, Generator Loss: 5.426397323608398\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 6.292546480894089, Generator Loss: 4.313553810119629\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 6.054940104484558, Generator Loss: 3.719538688659668\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 6.483374506235123, Generator Loss: 2.92628812789917\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 6/100, Discriminator Loss: 6.155518084764481, Generator Loss: 1.6110055446624756\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 6.4097461104393005, Generator Loss: 1.2838153839111328\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 7.060577154159546, Generator Loss: 1.4459428787231445\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 9/100, Discriminator Loss: 6.273823857307434, Generator Loss: 0.8600330352783203\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 7.0343815088272095, Generator Loss: 1.5383208990097046\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 6.194792032241821, Generator Loss: 1.0655760765075684\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 7.09048867225647, Generator Loss: 1.2050597667694092\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 6.831310272216797, Generator Loss: 1.3320338726043701\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 14/100, Discriminator Loss: 6.939178645610809, Generator Loss: 0.9890291094779968\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 15/100, Discriminator Loss: 7.498040556907654, Generator Loss: 0.7555416822433472\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 16/100, Discriminator Loss: 7.361822128295898, Generator Loss: 0.7767153382301331\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 17/100, Discriminator Loss: 7.445423722267151, Generator Loss: 0.8209059238433838\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 18/100, Discriminator Loss: 6.7262139320373535, Generator Loss: 0.7940877676010132\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 6.894546389579773, Generator Loss: 0.7586356401443481\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 20/100, Discriminator Loss: 7.114122748374939, Generator Loss: 0.7228598594665527\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 21/100, Discriminator Loss: 6.356812298297882, Generator Loss: 0.5966391563415527\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 7.321975469589233, Generator Loss: 0.7193362712860107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 5.924403786659241, Generator Loss: 0.7833287119865417\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 6.294174671173096, Generator Loss: 0.8421899080276489\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 7.096599698066711, Generator Loss: 0.8391987681388855\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 26/100, Discriminator Loss: 6.632721424102783, Generator Loss: 0.5218347311019897\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 27/100, Discriminator Loss: 6.960155487060547, Generator Loss: 0.5211498737335205\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 28/100, Discriminator Loss: 6.62216591835022, Generator Loss: 0.7139707803726196\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 29/100, Discriminator Loss: 7.084306240081787, Generator Loss: 0.677103579044342\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 30/100, Discriminator Loss: 7.835801601409912, Generator Loss: 0.5509409308433533\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 31/100, Discriminator Loss: 7.551696419715881, Generator Loss: 0.6524184346199036\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 32/100, Discriminator Loss: 6.059735417366028, Generator Loss: 0.8533000946044922\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 6.453338861465454, Generator Loss: 1.1292712688446045\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 6.352325767278671, Generator Loss: 1.051981806755066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 35/100, Discriminator Loss: 6.443108558654785, Generator Loss: 1.31907320022583\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 36/100, Discriminator Loss: 6.902158498764038, Generator Loss: 1.2668201923370361\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37/100, Discriminator Loss: 7.052588701248169, Generator Loss: 0.9336490035057068\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 5.96834921836853, Generator Loss: 1.1606608629226685\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch 39/100, Discriminator Loss: 6.769113063812256, Generator Loss: 0.792182207107544\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40/100, Discriminator Loss: 6.8865087032318115, Generator Loss: 0.6540958285331726\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 41/100, Discriminator Loss: 7.235883474349976, Generator Loss: 0.8405091762542725\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 42/100, Discriminator Loss: 7.218789577484131, Generator Loss: 0.500768780708313\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43/100, Discriminator Loss: 8.090321063995361, Generator Loss: 0.4741334915161133\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 44/100, Discriminator Loss: 7.98797345161438, Generator Loss: 0.43494564294815063\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 45/100, Discriminator Loss: 8.933737516403198, Generator Loss: 0.3904161751270294\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 8.516148805618286, Generator Loss: 0.3745006322860718\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 8.191953659057617, Generator Loss: 0.39092811942100525\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 7.071153163909912, Generator Loss: 0.3058398962020874\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 7.849926710128784, Generator Loss: 0.32722169160842896\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 8.403180837631226, Generator Loss: 0.4162638187408447\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51/100, Discriminator Loss: 8.659858703613281, Generator Loss: 0.47024187445640564\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 8.319369316101074, Generator Loss: 0.49332377314567566\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 8.148648381233215, Generator Loss: 0.46040230989456177\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 54/100, Discriminator Loss: 7.970559239387512, Generator Loss: 0.4133850932121277\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 55/100, Discriminator Loss: 8.400327444076538, Generator Loss: 0.761732816696167\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 6.961820483207703, Generator Loss: 0.5313824415206909\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 7.026852488517761, Generator Loss: 0.6939826607704163\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 6.968702554702759, Generator Loss: 0.5459046363830566\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 59/100, Discriminator Loss: 7.518149375915527, Generator Loss: 0.8000815510749817\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 60/100, Discriminator Loss: 6.774751424789429, Generator Loss: 0.6877515316009521\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 7.792612314224243, Generator Loss: 0.6451705098152161\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 7.197637557983398, Generator Loss: 0.7353386878967285\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 63/100, Discriminator Loss: 7.461743354797363, Generator Loss: 0.8809292912483215\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 64/100, Discriminator Loss: 7.913394093513489, Generator Loss: 0.6872488260269165\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 7.698941707611084, Generator Loss: 0.8200184106826782\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 66/100, Discriminator Loss: 7.496452569961548, Generator Loss: 0.7213308215141296\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 67/100, Discriminator Loss: 7.728735446929932, Generator Loss: 0.6207156181335449\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 68/100, Discriminator Loss: 7.571606159210205, Generator Loss: 0.41784971952438354\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 7.978176116943359, Generator Loss: 0.4201059937477112\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 8.579084873199463, Generator Loss: 0.41760027408599854\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 8.365790843963623, Generator Loss: 0.40530848503112793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 7.243483662605286, Generator Loss: 0.3799847364425659\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 8.354734659194946, Generator Loss: 0.3775821924209595\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 74/100, Discriminator Loss: 8.1260347366333, Generator Loss: 0.6210123300552368\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 7.954376220703125, Generator Loss: 0.6809136867523193\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 76/100, Discriminator Loss: 5.9532248973846436, Generator Loss: 0.9950759410858154\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 77/100, Discriminator Loss: 6.730572402477264, Generator Loss: 1.0111478567123413\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 5.3013957142829895, Generator Loss: 1.3323543071746826\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 5.682924330234528, Generator Loss: 0.8970283269882202\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 6.691053330898285, Generator Loss: 0.9427886009216309\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 81/100, Discriminator Loss: 6.2185098528862, Generator Loss: 0.7636574506759644\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 82/100, Discriminator Loss: 7.045040547847748, Generator Loss: 1.107086181640625\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 83/100, Discriminator Loss: 7.082837820053101, Generator Loss: 0.7893348932266235\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 84/100, Discriminator Loss: 7.161648750305176, Generator Loss: 0.5987690687179565\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 7.179886817932129, Generator Loss: 0.7189596891403198\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 7.270328640937805, Generator Loss: 0.6930405497550964\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 87/100, Discriminator Loss: 7.515817880630493, Generator Loss: 1.00514817237854\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 88/100, Discriminator Loss: 6.7625027894973755, Generator Loss: 1.5349775552749634\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 89/100, Discriminator Loss: 6.545666396617889, Generator Loss: 2.1215004920959473\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 90/100, Discriminator Loss: 6.811941564083099, Generator Loss: 1.7392557859420776\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 6.612725794315338, Generator Loss: 1.4043476581573486\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 92/100, Discriminator Loss: 7.0809537172317505, Generator Loss: 1.6923818588256836\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 93/100, Discriminator Loss: 7.558181881904602, Generator Loss: 1.6757519245147705\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 94/100, Discriminator Loss: 6.043986737728119, Generator Loss: 1.1695268154144287\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 7.0881155133247375, Generator Loss: 0.6947270035743713\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 8.270212769508362, Generator Loss: 0.7776618599891663\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 6.753820478916168, Generator Loss: 0.5429459810256958\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 7.35953426361084, Generator Loss: 0.7398590445518494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 99/100, Discriminator Loss: 7.029897689819336, Generator Loss: 1.3168435096740723\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 100/100, Discriminator Loss: 6.406478762626648, Generator Loss: 1.7646442651748657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output PReLU"
      ],
      "metadata": {
        "id": "1t5yp3jy47tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='PReLU'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='PReLU')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrXpirfE49Kz",
        "outputId": "3d878efb-c23a-4499-cedf-a3f02d69c49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 6.071852080523968, Generator Loss: 11.948670387268066\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2/100, Discriminator Loss: 6.050487671047449, Generator Loss: 10.022926330566406\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 6.067810297012329, Generator Loss: 7.469822883605957\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 4/100, Discriminator Loss: 6.2075101509690285, Generator Loss: 8.207794189453125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 5.722714081406593, Generator Loss: 6.514898300170898\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 6/100, Discriminator Loss: 5.7138590812683105, Generator Loss: 6.087976455688477\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 7/100, Discriminator Loss: 6.385417595505714, Generator Loss: 5.163500785827637\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 8/100, Discriminator Loss: 5.969915486872196, Generator Loss: 4.169054985046387\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 9/100, Discriminator Loss: 6.6824167519807816, Generator Loss: 4.329578876495361\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 10/100, Discriminator Loss: 5.85884827375412, Generator Loss: 3.4920005798339844\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 11/100, Discriminator Loss: 5.551520898938179, Generator Loss: 3.0588369369506836\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 5.732199490070343, Generator Loss: 2.9071075916290283\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 13/100, Discriminator Loss: 6.060162514448166, Generator Loss: 3.0051984786987305\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 5.611942321062088, Generator Loss: 3.1999590396881104\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 5.058021426200867, Generator Loss: 3.2321243286132812\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 5.014605537056923, Generator Loss: 3.194693088531494\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17/100, Discriminator Loss: 5.986299961805344, Generator Loss: 3.0162124633789062\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18/100, Discriminator Loss: 5.959111034870148, Generator Loss: 2.107088565826416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 5.634418994188309, Generator Loss: 2.5287413597106934\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 20/100, Discriminator Loss: 5.7929860800504684, Generator Loss: 1.9136083126068115\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 21/100, Discriminator Loss: 5.69097176194191, Generator Loss: 2.35308837890625\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 5.232804849743843, Generator Loss: 2.3155136108398438\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 5.174309849739075, Generator Loss: 3.1998119354248047\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 4.740870416164398, Generator Loss: 1.9169056415557861\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 25/100, Discriminator Loss: 4.175502270460129, Generator Loss: 2.442890167236328\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 26/100, Discriminator Loss: 4.955477774143219, Generator Loss: 2.2007689476013184\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 27/100, Discriminator Loss: 5.236675560474396, Generator Loss: 1.3842928409576416\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 4.9889794290065765, Generator Loss: 1.5855201482772827\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 4.944713592529297, Generator Loss: 1.4118825197219849\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 5.01997309923172, Generator Loss: 1.839738368988037\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31/100, Discriminator Loss: 4.413556635379791, Generator Loss: 1.9386661052703857\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 5.19827800989151, Generator Loss: 1.6340711116790771\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 5.035819485783577, Generator Loss: 1.5623891353607178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 5.47492715716362, Generator Loss: 2.234714984893799\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 35/100, Discriminator Loss: 5.670650899410248, Generator Loss: 2.9602551460266113\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 36/100, Discriminator Loss: 4.550263628363609, Generator Loss: 1.4153897762298584\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 37/100, Discriminator Loss: 5.192818909883499, Generator Loss: 2.7093653678894043\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 5.318614274263382, Generator Loss: 2.508373260498047\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 5.037924334406853, Generator Loss: 2.4987587928771973\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 40/100, Discriminator Loss: 4.981294006109238, Generator Loss: 1.8137940168380737\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41/100, Discriminator Loss: 4.907289415597916, Generator Loss: 2.0540571212768555\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 5.071057766675949, Generator Loss: 2.2270638942718506\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43/100, Discriminator Loss: 5.605400010943413, Generator Loss: 1.6691696643829346\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44/100, Discriminator Loss: 4.969713479280472, Generator Loss: 2.164555311203003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45/100, Discriminator Loss: 6.102645188570023, Generator Loss: 2.2075018882751465\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 46/100, Discriminator Loss: 4.620424181222916, Generator Loss: 2.3931541442871094\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 47/100, Discriminator Loss: 4.9765733778476715, Generator Loss: 2.0385565757751465\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 48/100, Discriminator Loss: 4.5300107300281525, Generator Loss: 2.2163920402526855\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 4.466048538684845, Generator Loss: 2.463413715362549\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 5.104156240820885, Generator Loss: 2.855862617492676\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51/100, Discriminator Loss: 3.8490594029426575, Generator Loss: 3.518895149230957\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 4.408596009016037, Generator Loss: 3.1650376319885254\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 53/100, Discriminator Loss: 5.2376076728105545, Generator Loss: 4.007871627807617\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 54/100, Discriminator Loss: 3.370747074484825, Generator Loss: 3.741983413696289\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 55/100, Discriminator Loss: 4.657653421163559, Generator Loss: 3.245638132095337\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 56/100, Discriminator Loss: 4.803138330578804, Generator Loss: 2.6910247802734375\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 57/100, Discriminator Loss: 4.821126386523247, Generator Loss: 3.390223979949951\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 58/100, Discriminator Loss: 4.774524122476578, Generator Loss: 2.747229814529419\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 59/100, Discriminator Loss: 3.860640898346901, Generator Loss: 2.804828643798828\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 3.9572707414627075, Generator Loss: 2.0994646549224854\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 61/100, Discriminator Loss: 4.114751517772675, Generator Loss: 2.141634464263916\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 3.7429765462875366, Generator Loss: 1.9778927564620972\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 63/100, Discriminator Loss: 4.9255291223526, Generator Loss: 2.113764762878418\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 64/100, Discriminator Loss: 3.829245448112488, Generator Loss: 1.8130199909210205\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 4.332176744937897, Generator Loss: 2.269845962524414\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 66/100, Discriminator Loss: 4.692211747169495, Generator Loss: 2.0115857124328613\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 67/100, Discriminator Loss: 4.406911671161652, Generator Loss: 2.4769349098205566\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 68/100, Discriminator Loss: 4.803158611059189, Generator Loss: 1.8814990520477295\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 4.849353134632111, Generator Loss: 2.3391404151916504\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 4.132770925760269, Generator Loss: 2.118668556213379\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 4.227808266878128, Generator Loss: 2.273297071456909\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 72/100, Discriminator Loss: 4.594854921102524, Generator Loss: 1.9089233875274658\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 4.224862158298492, Generator Loss: 2.2988405227661133\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 74/100, Discriminator Loss: 5.747492760419846, Generator Loss: 1.8219830989837646\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 75/100, Discriminator Loss: 4.010440409183502, Generator Loss: 2.666594982147217\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 76/100, Discriminator Loss: 3.9296280443668365, Generator Loss: 2.30800461769104\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 4.655952379107475, Generator Loss: 2.9461846351623535\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 4.746939033269882, Generator Loss: 1.987199306488037\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 79/100, Discriminator Loss: 4.3196510672569275, Generator Loss: 2.8625707626342773\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 4.095592454075813, Generator Loss: 1.8524634838104248\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 4.300253212451935, Generator Loss: 2.3388257026672363\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 82/100, Discriminator Loss: 3.899840325117111, Generator Loss: 2.8849198818206787\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 83/100, Discriminator Loss: 3.8096446096897125, Generator Loss: 2.7008867263793945\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 84/100, Discriminator Loss: 3.102649688720703, Generator Loss: 3.0097811222076416\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 3.654525578022003, Generator Loss: 2.5643904209136963\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 3.838218003511429, Generator Loss: 2.4304308891296387\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 3.650053471326828, Generator Loss: 1.7979178428649902\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 4.027839303016663, Generator Loss: 2.2235326766967773\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 3.912184029817581, Generator Loss: 2.3803181648254395\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 3.184597000479698, Generator Loss: 2.7976200580596924\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 4.448844611644745, Generator Loss: 1.9130573272705078\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 92/100, Discriminator Loss: 3.417089283466339, Generator Loss: 1.9844331741333008\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 93/100, Discriminator Loss: 3.73568657040596, Generator Loss: 2.3199622631073\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 94/100, Discriminator Loss: 4.108974143862724, Generator Loss: 1.9638924598693848\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 95/100, Discriminator Loss: 3.4356901347637177, Generator Loss: 2.1653685569763184\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 96/100, Discriminator Loss: 3.411584109067917, Generator Loss: 2.253763437271118\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 97/100, Discriminator Loss: 3.3456871509552, Generator Loss: 1.989823818206787\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 98/100, Discriminator Loss: 3.5478014945983887, Generator Loss: 1.6843266487121582\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 99/100, Discriminator Loss: 3.686246797442436, Generator Loss: 1.9165167808532715\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch 100/100, Discriminator Loss: 3.3190551847219467, Generator Loss: 2.1524229049682617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output sigmoid"
      ],
      "metadata": {
        "id": "uJuL5pCI4-Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='sigmoid'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmmaGozf4_dB",
        "outputId": "82a8b614-0549-465e-a783-4f22058515e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 1.1097444891929626, Generator Loss: 0.41673368215560913\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.9179717898368835, Generator Loss: 0.6204590797424316\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.6926451921463013, Generator Loss: 0.8950811624526978\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.5338695794343948, Generator Loss: 1.2148325443267822\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.5499390363693237, Generator Loss: 1.5115671157836914\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.5002485364675522, Generator Loss: 1.7907359600067139\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.4873367100954056, Generator Loss: 2.0511555671691895\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.45339806377887726, Generator Loss: 2.2747931480407715\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.4116286300122738, Generator Loss: 2.4979114532470703\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.41181105375289917, Generator Loss: 2.678974151611328\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.41200827062129974, Generator Loss: 2.8518872261047363\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.39479101821780205, Generator Loss: 2.965794086456299\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.39514706656336784, Generator Loss: 3.0930352210998535\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.4104836843907833, Generator Loss: 3.1933062076568604\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.4042191654443741, Generator Loss: 3.291934013366699\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.3225567229092121, Generator Loss: 3.3666257858276367\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.29759696684777737, Generator Loss: 3.4231395721435547\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.3556331545114517, Generator Loss: 3.4734463691711426\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.32902596332132816, Generator Loss: 3.5092434883117676\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.37389114685356617, Generator Loss: 3.5446739196777344\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.34793274383991957, Generator Loss: 3.5682311058044434\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.36014384776353836, Generator Loss: 3.5698068141937256\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.36852295882999897, Generator Loss: 3.6221466064453125\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.3146043121814728, Generator Loss: 3.6263701915740967\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.3008054383099079, Generator Loss: 3.608793258666992\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.2864406332373619, Generator Loss: 3.6155409812927246\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.3185857832431793, Generator Loss: 3.6350841522216797\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.3311327677220106, Generator Loss: 3.637671709060669\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.29035557620227337, Generator Loss: 3.5930469036102295\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.30663084611296654, Generator Loss: 3.6227023601531982\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.2481670156121254, Generator Loss: 3.6272196769714355\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.3210186120122671, Generator Loss: 3.624774932861328\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.26875064335763454, Generator Loss: 3.623027801513672\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.2679643612354994, Generator Loss: 3.636605739593506\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.2848365167155862, Generator Loss: 3.63362979888916\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.23918486572802067, Generator Loss: 3.575396776199341\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.27884052973240614, Generator Loss: 3.5878639221191406\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.2739993818104267, Generator Loss: 3.6257691383361816\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.25678781140595675, Generator Loss: 3.608999252319336\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.24468667060136795, Generator Loss: 3.608415126800537\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.3001925367861986, Generator Loss: 3.5809078216552734\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.23684001434594393, Generator Loss: 3.6242527961730957\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.25673748925328255, Generator Loss: 3.5601515769958496\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.23983772657811642, Generator Loss: 3.5742862224578857\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.24526398815214634, Generator Loss: 3.5713677406311035\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.2541179312393069, Generator Loss: 3.596627712249756\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.2511003091931343, Generator Loss: 3.55562162399292\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.213942039757967, Generator Loss: 3.5989692211151123\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.24223030544817448, Generator Loss: 3.641651153564453\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.223548524081707, Generator Loss: 3.585432291030884\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.21946057304739952, Generator Loss: 3.6525440216064453\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.2264911001548171, Generator Loss: 3.661647319793701\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.2759779244661331, Generator Loss: 3.620955228805542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.24383799359202385, Generator Loss: 3.610982894897461\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.2242826521396637, Generator Loss: 3.665902614593506\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.23130379803478718, Generator Loss: 3.632072925567627\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.21733274683356285, Generator Loss: 3.58166766166687\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.17777293361723423, Generator Loss: 3.6591758728027344\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.20021254569292068, Generator Loss: 3.608889579772949\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.21478579938411713, Generator Loss: 3.671393394470215\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.21828647516667843, Generator Loss: 3.6762735843658447\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.2052151896059513, Generator Loss: 3.6785576343536377\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.2009977474808693, Generator Loss: 3.661250352859497\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.19637997262179852, Generator Loss: 3.663935661315918\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.17373947240412235, Generator Loss: 3.7106590270996094\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.17698808200657368, Generator Loss: 3.690190553665161\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.1889746841043234, Generator Loss: 3.7526955604553223\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.19943757355213165, Generator Loss: 3.7173752784729004\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.1693676020950079, Generator Loss: 3.6919164657592773\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.1612584050744772, Generator Loss: 3.7165849208831787\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.20368852373212576, Generator Loss: 3.67783260345459\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.16699823178350925, Generator Loss: 3.7361066341400146\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.15928837284445763, Generator Loss: 3.663653612136841\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.18128401599824429, Generator Loss: 3.7670161724090576\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.15266906283795834, Generator Loss: 3.747025966644287\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.14327048882842064, Generator Loss: 3.749927282333374\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.1509589208289981, Generator Loss: 3.8247554302215576\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.17714254558086395, Generator Loss: 3.783573865890503\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.1329211499541998, Generator Loss: 3.7794313430786133\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.12330870609730482, Generator Loss: 3.823584794998169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.15841570682823658, Generator Loss: 3.7955214977264404\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.1676890254020691, Generator Loss: 3.7302536964416504\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.17029159143567085, Generator Loss: 3.8477840423583984\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.14270605333149433, Generator Loss: 3.8596553802490234\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.17832731548696756, Generator Loss: 3.7821598052978516\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.13198325596749783, Generator Loss: 3.7637481689453125\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.15402561705559492, Generator Loss: 3.823730230331421\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.14527480863034725, Generator Loss: 3.8421273231506348\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.13353740237653255, Generator Loss: 3.797135829925537\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.15839097555726767, Generator Loss: 3.807525634765625\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.14513747580349445, Generator Loss: 3.7525250911712646\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.14265716075897217, Generator Loss: 3.7913780212402344\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.139337919652462, Generator Loss: 3.874138593673706\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.1505405781790614, Generator Loss: 3.8296585083007812\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.13003446999937296, Generator Loss: 3.7713429927825928\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.12831838056445122, Generator Loss: 3.8870484828948975\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.12000645976513624, Generator Loss: 3.8113343715667725\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.1329512856900692, Generator Loss: 3.8086509704589844\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.1426877100020647, Generator Loss: 3.8104429244995117\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.13174192607402802, Generator Loss: 3.9436607360839844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output tanh"
      ],
      "metadata": {
        "id": "Bf16M9HK4_xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='tanh'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfNXYDQC5A1J",
        "outputId": "6b40aaaf-79d1-4a97-994e-1f0ed731a39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 1/100, Discriminator Loss: 5.843226844444871, Generator Loss: 13.424934387207031\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 2/100, Discriminator Loss: 6.847088024020195, Generator Loss: 10.910512924194336\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 5.639895021915436, Generator Loss: 7.778335094451904\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 4/100, Discriminator Loss: 5.635799504816532, Generator Loss: 6.488965034484863\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 5/100, Discriminator Loss: 5.991872280836105, Generator Loss: 6.761526107788086\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 6/100, Discriminator Loss: 6.1392310708761215, Generator Loss: 4.433080673217773\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 7/100, Discriminator Loss: 5.643904685974121, Generator Loss: 2.5555224418640137\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 8/100, Discriminator Loss: 6.082515060901642, Generator Loss: 2.3051300048828125\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 9/100, Discriminator Loss: 5.6740104258060455, Generator Loss: 1.214939832687378\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 10/100, Discriminator Loss: 5.176940083503723, Generator Loss: 1.43940007686615\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 6.219945102930069, Generator Loss: 0.9228074550628662\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 5.158442258834839, Generator Loss: 0.6538630127906799\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 13/100, Discriminator Loss: 5.051943242549896, Generator Loss: 0.5402432680130005\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 14/100, Discriminator Loss: 6.529381036758423, Generator Loss: 0.4911224842071533\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 15/100, Discriminator Loss: 5.6012173891067505, Generator Loss: 0.38908177614212036\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 5.3486363887786865, Generator Loss: 0.3876422941684723\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 17/100, Discriminator Loss: 5.90947163105011, Generator Loss: 0.3159174621105194\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 18/100, Discriminator Loss: 6.659639000892639, Generator Loss: 0.3157040774822235\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 19/100, Discriminator Loss: 6.1331906914711, Generator Loss: 0.30726292729377747\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 20/100, Discriminator Loss: 4.848050773143768, Generator Loss: 0.26669949293136597\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 5.540248870849609, Generator Loss: 0.26696985960006714\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 22/100, Discriminator Loss: 6.480221807956696, Generator Loss: 0.2409471571445465\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 23/100, Discriminator Loss: 5.622846245765686, Generator Loss: 0.2587403357028961\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 24/100, Discriminator Loss: 5.1725751757621765, Generator Loss: 0.2369793802499771\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 25/100, Discriminator Loss: 6.099251866340637, Generator Loss: 0.2121323198080063\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 26/100, Discriminator Loss: 5.012619078159332, Generator Loss: 0.2344573438167572\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 27/100, Discriminator Loss: 6.082475781440735, Generator Loss: 0.23880663514137268\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 28/100, Discriminator Loss: 6.061706781387329, Generator Loss: 0.23275455832481384\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 5.836982369422913, Generator Loss: 0.23232990503311157\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 30/100, Discriminator Loss: 6.287883102893829, Generator Loss: 0.26290979981422424\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 31/100, Discriminator Loss: 5.177869558334351, Generator Loss: 0.230862557888031\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 32/100, Discriminator Loss: 6.305363357067108, Generator Loss: 0.23688164353370667\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 5.372841417789459, Generator Loss: 0.24680495262145996\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 34/100, Discriminator Loss: 5.938794255256653, Generator Loss: 0.2723839282989502\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 35/100, Discriminator Loss: 5.112945854663849, Generator Loss: 0.2414759397506714\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 6.191523432731628, Generator Loss: 0.2798827886581421\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 37/100, Discriminator Loss: 4.827665567398071, Generator Loss: 0.3092395067214966\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 38/100, Discriminator Loss: 5.216558396816254, Generator Loss: 0.2717549204826355\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 5.416926145553589, Generator Loss: 0.2618585228919983\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40/100, Discriminator Loss: 5.690913438796997, Generator Loss: 0.293453186750412\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 41/100, Discriminator Loss: 6.250263094902039, Generator Loss: 0.28244614601135254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 42/100, Discriminator Loss: 5.977808177471161, Generator Loss: 0.3421704173088074\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 43/100, Discriminator Loss: 5.6091543436050415, Generator Loss: 0.3295155167579651\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 44/100, Discriminator Loss: 4.704392611980438, Generator Loss: 0.3495785593986511\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 45/100, Discriminator Loss: 5.242021441459656, Generator Loss: 0.347051739692688\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 6.301328897476196, Generator Loss: 0.3358110189437866\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 47/100, Discriminator Loss: 5.7585203647613525, Generator Loss: 0.34495097398757935\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 48/100, Discriminator Loss: 5.434259057044983, Generator Loss: 0.38766512274742126\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 49/100, Discriminator Loss: 5.216315269470215, Generator Loss: 0.3828090727329254\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 50/100, Discriminator Loss: 4.655482172966003, Generator Loss: 0.4521459639072418\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 51/100, Discriminator Loss: 4.891043066978455, Generator Loss: 0.43094688653945923\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 52/100, Discriminator Loss: 5.491332769393921, Generator Loss: 0.564144492149353\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 5.434509754180908, Generator Loss: 0.4254361689090729\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 54/100, Discriminator Loss: 5.01756078004837, Generator Loss: 0.4686264991760254\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 55/100, Discriminator Loss: 5.1062575578689575, Generator Loss: 0.47120898962020874\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 4.8790417313575745, Generator Loss: 0.5347582697868347\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 57/100, Discriminator Loss: 4.6915576457977295, Generator Loss: 0.47262078523635864\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 58/100, Discriminator Loss: 5.613019585609436, Generator Loss: 0.49042320251464844\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 59/100, Discriminator Loss: 5.1339738965034485, Generator Loss: 0.6708217859268188\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 60/100, Discriminator Loss: 4.995934367179871, Generator Loss: 0.5164167881011963\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 61/100, Discriminator Loss: 5.317501962184906, Generator Loss: 0.5208876132965088\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 62/100, Discriminator Loss: 4.913189053535461, Generator Loss: 0.4922964870929718\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 4.843400239944458, Generator Loss: 0.4613240361213684\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 64/100, Discriminator Loss: 5.16404402256012, Generator Loss: 0.5013148784637451\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 65/100, Discriminator Loss: 5.0071781873703, Generator Loss: 0.4867285490036011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 5.23796534538269, Generator Loss: 0.529473066329956\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 67/100, Discriminator Loss: 4.753270626068115, Generator Loss: 0.5299719572067261\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 68/100, Discriminator Loss: 4.918298840522766, Generator Loss: 0.6043075323104858\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 69/100, Discriminator Loss: 5.350566804409027, Generator Loss: 0.5071638822555542\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 70/100, Discriminator Loss: 5.040370345115662, Generator Loss: 0.5326699018478394\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 71/100, Discriminator Loss: 4.902932226657867, Generator Loss: 0.4759470820426941\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 4.7041401863098145, Generator Loss: 0.5943835377693176\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 73/100, Discriminator Loss: 5.421048164367676, Generator Loss: 0.7160646319389343\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 4.311031222343445, Generator Loss: 0.47351136803627014\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 75/100, Discriminator Loss: 4.765239119529724, Generator Loss: 0.49179187417030334\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 76/100, Discriminator Loss: 4.524936378002167, Generator Loss: 0.5410945415496826\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 77/100, Discriminator Loss: 4.557981610298157, Generator Loss: 0.49216902256011963\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 78/100, Discriminator Loss: 5.0472288727760315, Generator Loss: 0.46590378880500793\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 5.583721041679382, Generator Loss: 0.5421741008758545\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 80/100, Discriminator Loss: 4.715194523334503, Generator Loss: 0.4518594741821289\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 81/100, Discriminator Loss: 5.494644641876221, Generator Loss: 0.6028289794921875\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 82/100, Discriminator Loss: 5.3586777448654175, Generator Loss: 0.5182241201400757\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 83/100, Discriminator Loss: 4.840675055980682, Generator Loss: 0.5344817638397217\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 5.417490839958191, Generator Loss: 0.4863523542881012\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 85/100, Discriminator Loss: 4.852196633815765, Generator Loss: 0.584907591342926\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 86/100, Discriminator Loss: 4.16050660610199, Generator Loss: 0.47612470388412476\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 87/100, Discriminator Loss: 4.701309680938721, Generator Loss: 0.46960341930389404\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 88/100, Discriminator Loss: 5.215140402317047, Generator Loss: 0.7044073343276978\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 4.080149292945862, Generator Loss: 0.6545875072479248\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 90/100, Discriminator Loss: 4.730095326900482, Generator Loss: 0.5892956256866455\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 91/100, Discriminator Loss: 4.073654294013977, Generator Loss: 0.6645680069923401\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 92/100, Discriminator Loss: 4.682647109031677, Generator Loss: 0.5881751775741577\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 93/100, Discriminator Loss: 3.9616881608963013, Generator Loss: 0.48452621698379517\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 94/100, Discriminator Loss: 4.140689849853516, Generator Loss: 0.7170289754867554\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 95/100, Discriminator Loss: 4.46347713470459, Generator Loss: 0.6068112850189209\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 4.810640513896942, Generator Loss: 0.41729095578193665\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 97/100, Discriminator Loss: 4.409000992774963, Generator Loss: 0.5440919995307922\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 5.042330741882324, Generator Loss: 0.4365275800228119\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 99/100, Discriminator Loss: 3.823662281036377, Generator Loss: 0.44861900806427\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 100/100, Discriminator Loss: 4.454164206981659, Generator Loss: 0.5473960638046265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output softmax"
      ],
      "metadata": {
        "id": "iJUvUduT5BEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define the dimensions of the latent space (input to the generator)\n",
        "latent_dim = 100\n",
        "# Define the generator model\n",
        "generator = Sequential([\n",
        "    Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "    Dense(784, activation='softmax'),\n",
        "    Reshape((28, 28))\n",
        "])\n",
        "# Define the discriminator model\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the discriminator (binary crossentropy loss)\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Freeze the discriminator during the combined model training\n",
        "discriminator.trainable = False\n",
        "# Define the combined model (GAN)\n",
        "gan = Sequential([generator, discriminator])\n",
        "# Compile the GAN (binary crossentropy loss)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
        "\n",
        "# Function to generate random noise (latent points)\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    return np.random.randn(n_samples, latent_dim)\n",
        "# Function to generate fake images using the generator\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    latent_points = generate_latent_points(latent_dim, n_samples)\n",
        "    return generator.predict(latent_points)\n",
        "\n",
        "# Function to train the GAN\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n",
        "    half_batch = batch_size // 2\n",
        "    for epoch in range(n_epochs):\n",
        "        # Train the discriminator\n",
        "        real_images = np.random.randn(half_batch, 28, 28)\n",
        "        real_labels = np.ones((half_batch, 1))\n",
        "        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        fake_labels = np.zeros((half_batch, 1))\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "        # Train the generator (via the combined GAN model)\n",
        "        latent_points = generate_latent_points(latent_dim, batch_size)\n",
        "        misleading_targets = np.ones((batch_size, 1))\n",
        "        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n",
        "\n",
        "# Train the GAN\n",
        "train_gan(gan, generator, discriminator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bcJ5b2U5CV6",
        "outputId": "117209a8-a8aa-4ab0-d083-a10320431d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 1/100, Discriminator Loss: 0.6806151270866394, Generator Loss: 0.6926451921463013\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 2/100, Discriminator Loss: 0.7304114103317261, Generator Loss: 0.6926403641700745\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 3/100, Discriminator Loss: 0.6629149913787842, Generator Loss: 0.6927647590637207\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 4/100, Discriminator Loss: 0.7015375792980194, Generator Loss: 0.692947268486023\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 5/100, Discriminator Loss: 0.6804099082946777, Generator Loss: 0.6930649280548096\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 6/100, Discriminator Loss: 0.7300579249858856, Generator Loss: 0.6932889223098755\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 7/100, Discriminator Loss: 0.7556909620761871, Generator Loss: 0.6934186816215515\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 8/100, Discriminator Loss: 0.6640166640281677, Generator Loss: 0.6935855150222778\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 9/100, Discriminator Loss: 0.6389502584934235, Generator Loss: 0.6937710046768188\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.660092830657959, Generator Loss: 0.6939980387687683\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 11/100, Discriminator Loss: 0.621746301651001, Generator Loss: 0.6942093372344971\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 12/100, Discriminator Loss: 0.6298483610153198, Generator Loss: 0.6944601535797119\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 13/100, Discriminator Loss: 0.6447261869907379, Generator Loss: 0.6946780681610107\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 14/100, Discriminator Loss: 0.6516597270965576, Generator Loss: 0.6949619650840759\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 15/100, Discriminator Loss: 0.6284646093845367, Generator Loss: 0.6951876878738403\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 16/100, Discriminator Loss: 0.6642939448356628, Generator Loss: 0.6954193115234375\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 17/100, Discriminator Loss: 0.621849536895752, Generator Loss: 0.6956061124801636\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 18/100, Discriminator Loss: 0.6037516593933105, Generator Loss: 0.6958713531494141\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 19/100, Discriminator Loss: 0.66316357254982, Generator Loss: 0.6961621046066284\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.6437039077281952, Generator Loss: 0.6962424516677856\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 21/100, Discriminator Loss: 0.6059553027153015, Generator Loss: 0.6965417861938477\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 22/100, Discriminator Loss: 0.5970334410667419, Generator Loss: 0.6966924667358398\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 23/100, Discriminator Loss: 0.5865651965141296, Generator Loss: 0.6969263553619385\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 24/100, Discriminator Loss: 0.5549176782369614, Generator Loss: 0.6972520351409912\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 25/100, Discriminator Loss: 0.5652042031288147, Generator Loss: 0.6973919868469238\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 26/100, Discriminator Loss: 0.5826374292373657, Generator Loss: 0.6976571083068848\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 27/100, Discriminator Loss: 0.5892407596111298, Generator Loss: 0.697874903678894\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 28/100, Discriminator Loss: 0.5863171517848969, Generator Loss: 0.6981208324432373\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 29/100, Discriminator Loss: 0.5852335840463638, Generator Loss: 0.6982533931732178\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.5599175989627838, Generator Loss: 0.698540985584259\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 31/100, Discriminator Loss: 0.5656889528036118, Generator Loss: 0.6986639499664307\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 32/100, Discriminator Loss: 0.5736589729785919, Generator Loss: 0.6988867521286011\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 33/100, Discriminator Loss: 0.5599951297044754, Generator Loss: 0.699049174785614\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 34/100, Discriminator Loss: 0.5469006299972534, Generator Loss: 0.6993184685707092\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 35/100, Discriminator Loss: 0.559352234005928, Generator Loss: 0.6994749307632446\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 36/100, Discriminator Loss: 0.5603617429733276, Generator Loss: 0.6996599435806274\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 37/100, Discriminator Loss: 0.5586942583322525, Generator Loss: 0.6997953057289124\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 38/100, Discriminator Loss: 0.5563504695892334, Generator Loss: 0.6999496221542358\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 39/100, Discriminator Loss: 0.5498664677143097, Generator Loss: 0.7002442479133606\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.5583097487688065, Generator Loss: 0.7003021240234375\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 41/100, Discriminator Loss: 0.5471723079681396, Generator Loss: 0.7004096508026123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 42/100, Discriminator Loss: 0.5370408743619919, Generator Loss: 0.7006983160972595\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch 43/100, Discriminator Loss: 0.5141867101192474, Generator Loss: 0.700932502746582\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 44/100, Discriminator Loss: 0.5065649151802063, Generator Loss: 0.7010657787322998\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 45/100, Discriminator Loss: 0.5225153863430023, Generator Loss: 0.7012971639633179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 46/100, Discriminator Loss: 0.5157218277454376, Generator Loss: 0.7015517950057983\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch 47/100, Discriminator Loss: 0.5089877843856812, Generator Loss: 0.7017534971237183\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 48/100, Discriminator Loss: 0.5026118457317352, Generator Loss: 0.7019792795181274\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 49/100, Discriminator Loss: 0.47070880234241486, Generator Loss: 0.7021652460098267\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.5140999257564545, Generator Loss: 0.7024855017662048\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 51/100, Discriminator Loss: 0.49136000871658325, Generator Loss: 0.702673614025116\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch 52/100, Discriminator Loss: 0.4706963747739792, Generator Loss: 0.7028456926345825\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 53/100, Discriminator Loss: 0.4874180257320404, Generator Loss: 0.7032158374786377\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch 54/100, Discriminator Loss: 0.4937933385372162, Generator Loss: 0.7034628987312317\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch 55/100, Discriminator Loss: 0.5167584270238876, Generator Loss: 0.7035604119300842\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 56/100, Discriminator Loss: 0.4971511512994766, Generator Loss: 0.7038161158561707\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 57/100, Discriminator Loss: 0.4845917224884033, Generator Loss: 0.7039568424224854\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 58/100, Discriminator Loss: 0.45779943466186523, Generator Loss: 0.7042852640151978\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 59/100, Discriminator Loss: 0.463220439851284, Generator Loss: 0.7045595645904541\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.4895225763320923, Generator Loss: 0.7047303915023804\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 61/100, Discriminator Loss: 0.4773356169462204, Generator Loss: 0.7049770355224609\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 62/100, Discriminator Loss: 0.46757571399211884, Generator Loss: 0.7052286863327026\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 63/100, Discriminator Loss: 0.47440555691719055, Generator Loss: 0.7054399251937866\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 64/100, Discriminator Loss: 0.48560766875743866, Generator Loss: 0.7057459950447083\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 65/100, Discriminator Loss: 0.46099038422107697, Generator Loss: 0.7059034109115601\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 66/100, Discriminator Loss: 0.4882603883743286, Generator Loss: 0.7061518430709839\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 67/100, Discriminator Loss: 0.4375799223780632, Generator Loss: 0.7064352631568909\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 68/100, Discriminator Loss: 0.47459135949611664, Generator Loss: 0.7066020965576172\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 69/100, Discriminator Loss: 0.4638703465461731, Generator Loss: 0.7067550420761108\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.4548664167523384, Generator Loss: 0.7069081664085388\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 71/100, Discriminator Loss: 0.4354512616991997, Generator Loss: 0.7073095440864563\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 72/100, Discriminator Loss: 0.4692167341709137, Generator Loss: 0.7074436545372009\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 73/100, Discriminator Loss: 0.4577263742685318, Generator Loss: 0.7078880071640015\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 74/100, Discriminator Loss: 0.4857385754585266, Generator Loss: 0.708036482334137\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 75/100, Discriminator Loss: 0.45131565630435944, Generator Loss: 0.7083936929702759\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 76/100, Discriminator Loss: 0.46269214153289795, Generator Loss: 0.7085545063018799\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 77/100, Discriminator Loss: 0.46008092164993286, Generator Loss: 0.7087327241897583\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 78/100, Discriminator Loss: 0.4298976957798004, Generator Loss: 0.7089188694953918\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 79/100, Discriminator Loss: 0.4559854194521904, Generator Loss: 0.7091276049613953\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.4476396143436432, Generator Loss: 0.709435224533081\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 81/100, Discriminator Loss: 0.4490627646446228, Generator Loss: 0.7095455527305603\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 82/100, Discriminator Loss: 0.42526839673519135, Generator Loss: 0.7100873589515686\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 83/100, Discriminator Loss: 0.44268281012773514, Generator Loss: 0.7102881669998169\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 84/100, Discriminator Loss: 0.43855245411396027, Generator Loss: 0.710338830947876\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 85/100, Discriminator Loss: 0.4334711879491806, Generator Loss: 0.7107406258583069\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 86/100, Discriminator Loss: 0.42803582549095154, Generator Loss: 0.711067259311676\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 87/100, Discriminator Loss: 0.433745801448822, Generator Loss: 0.7112519145011902\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 88/100, Discriminator Loss: 0.4340227395296097, Generator Loss: 0.7115151882171631\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 89/100, Discriminator Loss: 0.44700582325458527, Generator Loss: 0.7117929458618164\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.4334554597735405, Generator Loss: 0.7120159864425659\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch 91/100, Discriminator Loss: 0.42247477173805237, Generator Loss: 0.7121574282646179\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 92/100, Discriminator Loss: 0.4421400874853134, Generator Loss: 0.7124888896942139\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 93/100, Discriminator Loss: 0.424020953476429, Generator Loss: 0.7127329111099243\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch 94/100, Discriminator Loss: 0.4349802955985069, Generator Loss: 0.712934136390686\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 95/100, Discriminator Loss: 0.4292996674776077, Generator Loss: 0.7133578658103943\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 96/100, Discriminator Loss: 0.43027549237012863, Generator Loss: 0.7135623693466187\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 97/100, Discriminator Loss: 0.41593874990940094, Generator Loss: 0.7140151262283325\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 98/100, Discriminator Loss: 0.4325346201658249, Generator Loss: 0.7139129042625427\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 99/100, Discriminator Loss: 0.4114293083548546, Generator Loss: 0.7143377661705017\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Epoch 100/100, Discriminator Loss: 0.4153352379798889, Generator Loss: 0.7145787477493286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion\n",
        "Best output activation function = softmax (?). Epoch 100/100, Discriminator Loss: 0.4153352379798889, Generator Loss: 0.7145787477493286\n"
      ],
      "metadata": {
        "id": "mzCgMzXl5Cqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**explaination from chatgpt. to be verified the credibility:\n",
        "\n",
        "To determine the \"best\" result:\n",
        "\n",
        "The discriminator loss should ideally be low, indicating that the discriminator can distinguish well between real and fake samples.\n",
        "\n",
        "The generator loss should ideally be high, indicating that the generator can produce samples that are challenging for the discriminator to classify as fake.\n",
        "\n",
        "From the provided results, the last epoch (Epoch 100/100) with the discriminator loss of 0.415 and the generator loss of 0.715 seems to be the best result.\n",
        "\n",
        "This is because the discriminator loss is relatively low, indicating good discrimination capability, and the generator loss is moderately high, indicating that the generator is producing samples that are challenging for the discriminator."
      ],
      "metadata": {
        "id": "zxa9Jq3BBHKv"
      }
    }
  ]
}